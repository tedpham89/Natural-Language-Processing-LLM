{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3M1CFw-VT5vI"
   },
   "source": [
    "#Preamble\n",
    "\n",
    "This mini-project involves working through all the steps of a problem, whereas prior assignments asked you to just implement core functions. We will give you a dataset, but you will also have the opportunity to manipulate the data in ways that you find beneficial to the overall project and to explain why and how those manipulations mattered. This will be in addition to building the model from scratch, developing the training loop, and implementing testing. The code will be accompanied by a report written into the notebook.\n",
    "\n",
    "This project will have you working with attention mechanism, in a new type of system for question-answering. This will provide you with experience working with attention mechanisms while not directly working with transformers.\n",
    "\n",
    "This assignment is not autograded. You can modify any code cells as long as you achieve the requirements of each graded component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhZzhjGaTj9P"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Memory networks learn to access external memory stores (a database or, in the case of this assignment, a dictionary). Key-Value Memory Networks specifically assume that the external memory store is organized as a dictionary with keys and values. In theory memory networks are useful when one wants a neural network to be able to know a lot of information but we don't want to try to encode that information directly into the parameters of the network. This means information can be changed in the external memory database without retraining the neural network.\n",
    "\n",
    "Given a question, e.g., \"Where was Alexander Hamilton born?\", a key-value memory network learns an embedding such that the question has a high cosine similarity to a particular key in the external dictionary. Because there are many keys that need to be matched against, key-value memory networks implement an attention-scoring mechanism to select a key. Because attention is a probabilistic score, the key-value memory network retrieves a sum of embeddings weighted according to the attention score. This weighted embedding is then compared to values using a second attention-scoring mechanism. The value with the highest cosine similarity can then be retrieved and returned as the answer.\n",
    "\n",
    "Memory networks were an important part of the evolution of question-answering systems that have been eclipsed by transformers. However, the attention mechanism in a key-value memory network is very similar to the self-attention inside a transformer, so implementing a key-value memory network is a really great way to experiment and learn about self-attention without the added complexity of transformers.\n",
    "\n",
    "Key-value memory networks are also closely related to retieval-based generation networks, except we will be retrieving facts from a dictionary instead of via the internet. However, the embedding of retrieved data will be similar.\n",
    "\n",
    "Key-value memory networks are described in this [paper](https://arxiv.org/abs/1606.03126). It is recommended that you read the paper, but we will also walk through the steps you will need to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLQP14bxNXDx"
   },
   "source": [
    "# Some imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAe6-NtARNjW"
   },
   "source": [
    "You may add imports as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "id": "JfnqkHKkITC3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "id": "AviW7dfn6pUi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQM96JBsVHwF"
   },
   "source": [
    "Unidecode is useful for getting rid of issues that arise from unicode. This should not be used if we care about unicode, but for the purposes of an instructional exercise, it eliminates a lot of edge cases that come up with unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "id": "EYuVdhWfAcGQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\trung\\miniconda3\\envs\\cs7650_hw\\lib\\site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "id": "3E_fVmV2_8ub"
   },
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_bDmt5iSD_j"
   },
   "source": [
    "If you need to have a reduced vocabulary, you can create an unknown \"unk\" token and add it to the vocabulary. Make sure the token index in the vocabulary and `UNK_ID` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "id": "DDHhoxzyAByu"
   },
   "outputs": [],
   "source": [
    "UNK = 'unk'\n",
    "UNK_ID = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl6J8BwVpHCw"
   },
   "source": [
    "# Some utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LVVnmlNRKTp"
   },
   "source": [
    "You may edit these as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KF3VeFoSenc"
   },
   "source": [
    "Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "id": "CPwG_8VrNUop"
   },
   "outputs": [],
   "source": [
    "# Stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= [ps.stem(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDg9vUiDShG-"
   },
   "source": [
    "Simple tokenizer that only keeps letters and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "id": "eEofSDrQ9fg_"
   },
   "outputs": [],
   "source": [
    "def tokenize(line):\n",
    "    line = re.sub(r'[^a-zA-Z0-9]', ' ', unidecode.unidecode(line)) # remove punctuation\n",
    "    line = line.lower().split()  # lower case\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IH2QW9FjSrJh"
   },
   "source": [
    "A standard vocabulary object class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "id": "25siAXsXOJj9"
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, name = 'vocab'):\n",
    "        self.name = name\n",
    "        self._word2index = {}\n",
    "        self._word2count = {}\n",
    "        self._index2word = {}\n",
    "        self._n_words = 0\n",
    "\n",
    "    def get_words(self):\n",
    "      return list(self._word2count.keys())\n",
    "\n",
    "    def num_words(self):\n",
    "      return self._n_words\n",
    "\n",
    "    def word2index(self, word):\n",
    "      return self._word2index[word]\n",
    "\n",
    "    def index2word(self, word):\n",
    "      return self._index2word[word]\n",
    "\n",
    "    def word2count(self, word):\n",
    "      return self._word2count[word]\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in tokenize(sentence):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self._word2index:\n",
    "            self._word2index[word] = self._n_words\n",
    "            self._word2count[word] = 1\n",
    "            self._index2word[self._n_words] = word\n",
    "            self._n_words += 1\n",
    "        else:\n",
    "            self._word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esAT3lG1S5cV"
   },
   "source": [
    "Make a bag of words frmo a sentence, given a vocabulary. Can return a bag of word counts or a a bag of word presences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "id": "oKJP2y8g-TFE"
   },
   "outputs": [],
   "source": [
    "# ORIGINAL\n",
    "# def multihot(s, vocab, preserve_counts = False):\n",
    "#   tokens = np.array([vocab.word2index(t) for t in tokenize(s)])\n",
    "#   mhot = np.zeros((tokens.size, vocab.num_words()))\n",
    "#   mhot[np.arange(tokens.size), tokens] = 1\n",
    "#   if preserve_counts:\n",
    "#     return mhot.sum(0)\n",
    "#   else:\n",
    "#     return mhot.sum(0) >= 1\n",
    "\n",
    "# Recreate multihot to add UNK\n",
    "def multihot(s, vocab, preserve_counts = False):\n",
    "    # tokenize\n",
    "    tokens = tokenize(s)\n",
    "\n",
    "    # Convert to indices but replace out vocab word with unk\n",
    "    token_indices = []\n",
    "    for token in tokens:\n",
    "        if token in vocab._word2index:\n",
    "           token_indices.append(vocab._word2index[token])\n",
    "        else:         # token not in vocab\n",
    "            if UNK in vocab._word2index:\n",
    "                token_indices.append(vocab._word2index[UNK])\n",
    "\n",
    "    # Create vector\n",
    "    token_indices = np.array(token_indices)\n",
    "    # Switch to 1d just easier to understand\n",
    "    mhot = np.zeros(vocab.num_words())\n",
    "    unique_indices, counts = np.unique(token_indices, return_counts=True)\n",
    "    if preserve_counts:\n",
    "        mhot[unique_indices] = counts\n",
    "    else:\n",
    "        mhot[unique_indices] = 1\n",
    "\n",
    "    return mhot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w8BflMUTLW_"
   },
   "source": [
    "If you have a reduced vocabulary, use this to replace out-of-vocab words. If you use this, you may want to merge it with `multihot` above to avoid tokenizing twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "LfvAfjEl7Z6j"
   },
   "outputs": [],
   "source": [
    "def unkit(s, vocab):\n",
    "  return ' '.join(list(map(lambda x: UNK if x not in vocab._word2index else x, tokenize(s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHZm-bAanrrf"
   },
   "source": [
    "# Part A: Download and Process Data (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-L61V7tVPok"
   },
   "source": [
    "This dataset contains the information in tables that are commonly used in Wikipedia biography pages. Each person has different rows of information pertaining to their notable accomplishments and details about their life. There are a large number of types of information that can appear as rows in the biography tables, however they are relatively uniform. We call the keys of the rows \"relations\".\n",
    "\n",
    "For example [Alexander Hamilton](https://en.wikipedia.org/wiki/Alexander_Hamilton) has information about the President he worked for as Secretary of State, birth date, date of death, parents' names, etc.\n",
    "\n",
    "The code below will download the dataset and process it to create two things:\n",
    "- `DB`: a hash table that map titles of biography wikipedia articles to table information. The table information is represented as a nested hash table containing relations as keys, and associated values. For example, `DB['alexander hamilton'] = {'party': 'federalist',\n",
    " 'spouse': 'elizabeth schuyler', ...}`\n",
    "- `VOCAB`: A vocabulary object that maps words to tokens and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "id": "PYzcdAR2ntvm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'wikipedia-biography-dataset' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rlebret/wikipedia-biography-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "RZEHbtftn17L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z00\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z01\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z02\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z03\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z04\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z05\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z06\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z07\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z08\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z09\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z10\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z11\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z12\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z13\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z14\n",
      "wikipedia-biography-dataset\\wikipedia-biography-dataset.z15\n",
      "        1 file(s) copied.\n",
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 58B5-434B\n",
      "\n",
      " Directory of c:\\Users\\trung\\Documents\\CS7650 NLP\\hw5-student\n",
      "\n",
      "07/27/2025  12:27 AM       333,998,704 tmp.zip\n",
      "               1 File(s)    333,998,704 bytes\n",
      "               0 Dir(s)  570,678,194,176 bytes free\n",
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "!copy /b wikipedia-biography-dataset\\wikipedia-biography-dataset.z* tmp.zip\n",
    "!dir tmp.zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile('tmp.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')  \n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rRYqmfSTcw0"
   },
   "source": [
    "Get all the wikipedia titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "id": "mdVrlCf-4TAq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582659\n"
     ]
    }
   ],
   "source": [
    "train_titles = []\n",
    "with open(\"wikipedia-biography-dataset/train/train.title\", \"r\", encoding=\"utf-8\") as file:\n",
    "  for line in file:\n",
    "    train_titles.append(line.rstrip())\n",
    "print(len(train_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOkCic0NTeuS"
   },
   "source": [
    "Boxes contain all the information, with each line corresponding to a title in `titles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "id": "C80pu63x4o-Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582659\n"
     ]
    }
   ],
   "source": [
    "train_boxes = []\n",
    "with open(\"wikipedia-biography-dataset/train/train.box\", \"r\") as file:\n",
    "  for line in file:\n",
    "    train_boxes.append(line.rstrip())\n",
    "print(len(train_boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63cxS1DWTk0h"
   },
   "source": [
    "This will make the DB object, a dictionary of dictionaries for each wikipedia title, which is more or less the same as names. This function only keeps politicians (containing the \"office\" key term) and strips out information about images. It can be improved in many ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "id": "Pr97KJLc4v7v"
   },
   "outputs": [],
   "source": [
    "# Make a dictionary of dictionaries\n",
    "def make_db(titles, boxes):\n",
    "  db = {} # The DB\n",
    "  # Iterate through titles\n",
    "  for i in tqdm(range(len(titles))):\n",
    "    box = boxes[i] # Grab the corresponding box information\n",
    "    d  = {} # Inner dictionary\n",
    "    # Build a dict for the ith entry\n",
    "    # grab each key:value pair\n",
    "    for pair in re.findall(r'([a-zA-Z_]+)[0-9]*\\:([\\w\\d]+)', box):\n",
    "      key, value = pair\n",
    "      # Do a bit of cleaning\n",
    "      key = key.strip()\n",
    "      value = value.strip()\n",
    "      # If the key contains the word image, we probably don't want to keep it\n",
    "      if 'image' not in key:\n",
    "        # The regex maintains underscores, strip those off\n",
    "        if key[-1] == '_':\n",
    "          key = key[:-1]\n",
    "        # Make a new entry in inner dictionary if we don't have one\n",
    "        if key not in d:\n",
    "          d[key] = value\n",
    "        # Keys with compound values are split up, which is annoying, so put them back together\n",
    "        else:\n",
    "          d[key] += ' ' + value\n",
    "    # If it has an office key, keep it.\n",
    "    if 'office' in d:\n",
    "      db[titles[i]] = d\n",
    "  return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9hB1o63U45e"
   },
   "source": [
    "Build the vocab from the DB. Convert the whole thing into a string, tokenize it, and feed the surviving words into the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "id": "p13O5dcVvdZu"
   },
   "outputs": [],
   "source": [
    "def make_vocab(DB):\n",
    "  # Make the vocab object\n",
    "  vocab = Vocab()\n",
    "  # Tokenize the data by converting the entire DB into a string\n",
    "  tokens = tokenize(str(DB))\n",
    "  # Iterate through all the tokens (tqdm provides a progress bar)\n",
    "  for t in tqdm(tokens):\n",
    "    vocab.add_word(t)\n",
    "  print(\"make vocab \",vocab.num_words())\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zkjf7mbAVA9H"
   },
   "source": [
    "If you want to discard rare words, this will rebuild the vocab. This is just an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "448Ww-BFtBL3"
   },
   "outputs": [],
   "source": [
    "def reduce_vocab(vocab, min_word_occurrence = 2):\n",
    "  # make a new vocab\n",
    "  vocab2 = Vocab(\"top\")\n",
    "  # Add the UNK token\n",
    "  vocab2.add_word(UNK)\n",
    "  # Iterate through vocabulary\n",
    "  for w in list(vocab._word2count.keys()):\n",
    "    count = vocab._word2count[w]\n",
    "    idx = vocab._word2index[w]\n",
    "    # If the word count passes threshold, add it to the new vocabulary object\n",
    "    if count >= min_word_occurrence:\n",
    "      vocab2.add_word(w)\n",
    "      vocab2._word2count[w] = count\n",
    "  # Return the new vocabulary object\n",
    "  return vocab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVS602YPVE9N"
   },
   "source": [
    "Make the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "id": "cio_ZwncrGf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 582659/582659 [00:32<00:00, 18166.59it/s]\n"
     ]
    }
   ],
   "source": [
    "DB = make_db(train_titles, train_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETLqtWtyVKLE"
   },
   "source": [
    "Make the VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "id": "lc7oi3p54SOb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997937/2997937 [00:01<00:00, 2099087.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make vocab  96093\n",
      "96093\n",
      "Original vocab size  96093\n",
      "Reduced vocab size  47085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "VOCAB = make_vocab(DB)\n",
    "print(VOCAB.num_words())\n",
    "\n",
    "# Modify to reduce vocab.\n",
    "reduced_vocab = reduce_vocab(VOCAB, min_word_occurrence = 3)\n",
    "print(\"Original vocab size \",VOCAB.num_words())\n",
    "print(\"Reduced vocab size \", reduced_vocab.num_words())\n",
    "\n",
    "VOCAB = reduced_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9AP3Dcle5VC"
   },
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiTQxguSXEuq"
   },
   "source": [
    "You may find it useful to save the processed dataset to your Google Drive.\n",
    "\n",
    "It is recommended that you save the file to your Google Drive. To mount your Google Drive, open the file icon on the left side of the screen to get to the option). To save the file in your Google Drive use the path `'drive/MyDrive/filename'`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "id": "6DNxueU-gpz_"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "id": "DwagcDU_Ut2Q"
   },
   "outputs": [],
   "source": [
    "# with open(\"drive/MyDrive/data\", \"wb\") as f:\n",
    "#   pickle.dump(DB, f, protocol=None, fix_imports=True, buffer_callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "id": "WS6a8EtX_h0F"
   },
   "outputs": [],
   "source": [
    "# with open('drive/MyDrive/vocab', 'wb') as f:\n",
    "#     pickle.dump(VOCAB, f, protocol=None, fix_imports=True, buffer_callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"saveddata\", exist_ok=True)\n",
    "\n",
    "# Save DB\n",
    "with open(\"saveddata/DB.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DB, f)\n",
    "\n",
    "# Save VOCAB\n",
    "with open(\"saveddata/VOCAB.pkl\", \"wb\") as f:\n",
    "    pickle.dump(VOCAB, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzlH6IKhe_Qa"
   },
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AlkMbibXYWg"
   },
   "source": [
    "If you have saved the processed data in your Google Drive, you can re-load it with these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "id": "ZCaiBhdvCa_C"
   },
   "outputs": [],
   "source": [
    "# with open(\"drive/MyDrive/vocab\", \"rb\") as f:\n",
    "#   VOCAB = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "id": "IinOyL_4C1Hx"
   },
   "outputs": [],
   "source": [
    "# with open(\"drive/MyDrive/data\", \"rb\") as f:\n",
    "#   DB = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VOCAB\n",
    "with open(\"saveddata/VOCAB.pkl\", \"rb\") as f:\n",
    "    VOCAB = pickle.load(f)\n",
    "\n",
    "# Load DB\n",
    "with open(\"saveddata/DB.pkl\", \"rb\") as f:\n",
    "    DB = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcZcFUxrfCnB"
   },
   "source": [
    "## Data example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKKoOuLCVYxd"
   },
   "source": [
    "Get to know your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "id": "dbLkOyB2pp_M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'alexander hamilton',\n",
       " 'office': '1st united states secretary of the treasury senior officer of the army delegate to the congress of the confederation from new york',\n",
       " 'president': 'george washington john adams',\n",
       " 'term_start': 'september 11 1789 december 14 1799 november 3 1788 november 4 1782',\n",
       " 'term_end': 'january 31 1795 june 15 1800 march 2 1789 june 21 1783',\n",
       " 'predecessor': 'position established george washington egbert benson seat established',\n",
       " 'successor': 'oliver wolcott jr james wilkinson seat abolished seat abolished',\n",
       " 'birth_date': '11 january 1755',\n",
       " 'birth_place': 'charlestown nevis british west indies',\n",
       " 'death_date': 'july 12 1804 aged 47 or 49',\n",
       " 'death_place': 'new york city new york u',\n",
       " 'party': 'federalist',\n",
       " 'spouse': 'elizabeth schuyler',\n",
       " 'children': 'philip angelica alexander james alexander john church william stephen eliza holly phil',\n",
       " 'alma_mater': 'kings college new york',\n",
       " 'religion': 'presbyterian episcopalian convert',\n",
       " 'signature': 'alexander hamilton signaturert',\n",
       " 'allegiance': 'flag_of_new_york _ 1778 svg 23px new york 1775 1777 united states 1795 23px 1777 1800',\n",
       " 'branch': 'flag_of_new_york _ 1778 svg 23px new york company of artillery united states 1777 23px continental army 25px united states army',\n",
       " 'serviceyears': '1775 1776 militia 1776 1781 1798 1800',\n",
       " 'rank': '23px',\n",
       " 'article_title': 'alexander hamilton'}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB[\"alexander hamilton\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITACHJTWfE5m"
   },
   "source": [
    "# Part B: Implement the Key-Value Memory Network (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQqLE-fcI_43"
   },
   "source": [
    "This [paper](https://arxiv.org/abs/1606.03126) describes the key-value memory networks in detail, which is also sketched out below.\n",
    "\n",
    "A key-value memory network takes a natural language question. This question will be converted into a bag-of-words (i.e., a multihot) Call this $x$ and it is a 1D tensor of vocabulary length.\n",
    "\n",
    "![KVMemNet architecture](https://github.com/markriedl/kvmemnet-assignment/blob/32479dd1e88a9f8dfc72f11ccb8e9e0e1f78905f/kvmemnet-inside.png?raw=true)\n",
    "\n",
    "The KVMemNet will contain a linear layer (or embedding layer) that will produce a 1D embedding of the question $q=A(x)$.\n",
    "\n",
    "The KVMemNet will also take in a stack of keys as a tensor of shape `num_keys x vocab_size`. Each row is embedded using the same embedding, $k=A(keys)$, producing a tensor of shape `num_keys x embed_dim`. How this stack of keys is chosen will be discussed below.\n",
    "\n",
    "The KVMemNet will take in a third input, a stack of values associated with the stack of keys. This will also be of shape `num_values x vocab_size`. Each row is embedded using the same embedding, $v=A(values)$, producing a tensor of shape `num_keys x embed_dim`.\n",
    "\n",
    "The KVMemNet will also contain a second linear embedding layer, $B$. More on this later.\n",
    "\n",
    "Once we have `q`, `k`, and `v` embeddings, the next step is to use `q` and `k` to compute attention scores that can be applied against `v`. Think of $A$ as learning how to make questions and the keys that should match against values that have received the same treatment.\n",
    "\n",
    "The attention scores `p` are computed by taking the inner-product (`torch.inner()`) between `q` and `k`. The result will be a 1D tensor with `num_keys` length. Use softmax so that `p` contains scores between 1.0 and 0.0.\n",
    "\n",
    "You may be wondering why there isn't a non-linearity such as a sigmoid or ReLU after the linear layer. Softmax is a non-linearity.\n",
    "\n",
    "Next apply the `p` attention scores against `v` to apply a weight against each value in the stack of values. One should be highly weighted and the rest less weighted. Sum all the weighted values up to create a 1D tensor `o` of feature weights of length `embed_dim`. `p` can be thought of as how much of each value gets selected. Then they all get combined together and the feature weights are proportional to how much each value was attended to. The `torch.matmul()` can do the multiplication and summing in one step.\n",
    "\n",
    "The KVMemNet forward function should return this tensor of feature weights `o`.\n",
    "\n",
    "A quick note on `k` and `v`. We can't send the entire set of keys and values in our database through the network's forward function. Instead there should be a selection mechanism that selects just a subset of the database. This subset should contain the best key for the question $x$ to match against, and its corresponding value. We assume that a shallow selection process can narrow down the key-value pairs to a relatively small set, one of which will be best. For example, if the question involves \"Alexander Hamilton\", we can reasonably guess that the best key-value pair is in the part of the database associated with the named person.\n",
    "\n",
    "We are not done though. What about our linear layer $B$? Suppose variable `Y` contains our entire set of values in our databse as bags of words. $B$ is going to be used to embed our entire set of database values $y=B(Y)$. $B$ can be thought of as learning how to make all the values look like the feature weights output by the model such that the highest cosine similarity corresponds to the correct value taken from *all* values in the database.\n",
    "\n",
    "$B$ should live inside the KVMemNet object so that its parameters become trainable, but notice that we do not use $B$ in the KVMemNet's forward function. $B$ will get used to prepare the stack of all values in the database for training. It will bet used in the training loop but outside of the forward function. This is a bit unusual, but necessary to figure out the correct target (the true index of the best value to match against) for training.\n",
    "\n",
    "The above explantion only implements *single-hop* retrieval. *multi-hop* retrieval allows the results of one retrieval to inform a second (and third and so on) to get the right retrieval. This would be used in the case where the answer cannot be inferred directly from the question in a single retrieval, such as \"What was the founding date of the country that Alexander Hamilton was born in?\". To implement multi-hop retrieval, the KVMemNet will have additional linear layers $R_1...R_n$. Each $R_{i}$ will do a linear transform on `q` then attention will score and retrieve values as feature weights `o`. This will be sent to the next $R_{i+1}$ and so on until the hops are complete. This final `o` will be returned.\n",
    "\n",
    "For this assignment is is sufficient to only do *single-hop* retrieval.\n",
    "\n",
    "The above explanation does not include consideration of batching. You may want to add a batch dimension as the first dimension and input a batch as a set of questions, a set of stacks of keys, and a set of stacks of values. To do this, functions like `.inner()`, `.mm()`, and`.matmul()` will not work. Instead use `.bmm()` which handles batching correctly. You will probably need to do some `.squeeze()` and `.unsqueeze()` operations to make sure your tensors are the correct shapes.\n",
    "\n",
    "Instead of bag-of-words, one may also consider first converting each question, key, and value into a general set of embeddings such as [GLoVe](https://nlp.stanford.edu/projects/glove/). To do this one will need to consider how to combine words--convert each word into an embedding vector and then add the vectors together (or maybe average them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSf1SSX7bgdE"
   },
   "source": [
    "**Complete the key-value memory net code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "id": "9zex3XZzw0-l"
   },
   "outputs": [],
   "source": [
    "class KVMemNet(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_dim):\n",
    "    super(KVMemNet, self).__init__()\n",
    "    self.vocab_size = vocab_size\n",
    "    self.embed_dim = embed_dim\n",
    "    \n",
    "    # Embedding layer A: shared for questions and keys\n",
    "    self.A = nn.Linear(vocab_size, embed_dim)\n",
    "    \n",
    "    # Embedding layer B: for database values (used in training loop)\n",
    "    self.B = nn.Linear(vocab_size, embed_dim)\n",
    "\n",
    "  def forward(self, x, keys, values):\n",
    "    # print(\"x shape\",x.shape)\n",
    "    # print(\"keys shape\", keys.shape)\n",
    "    # print(\"value shape\", values.shape)\n",
    "    \n",
    "    # Handle different dimensdion intead of batch_size\n",
    "    if x.dim() == 1:\n",
    "      x = x.unsqueeze(0)                  # shape (1,vocab_sz)\n",
    "      keys = keys.unsqueeze(0)            # shape (1,num_keys, vocab_size)\n",
    "      values = values.unsqueeze(0)        # shape (1, num_keys, vocab_size)\n",
    "\n",
    "    # Embedding q,k,v\n",
    "    q = self.A(x)                         # (batch_size, embed_dim)\n",
    "    k = self.A(keys)                      # (batch_size, num_keys, embed_dim)\n",
    "    v = self.A(values)                    # (batch_size, num_keys, embed_dim)\n",
    "\n",
    "    # Modify querry\n",
    "    q = q.unsqueeze(1)                    # (batch_size, 1, embed_dim)\n",
    "    # k.transpose(1,2) shape (batch_size, embed_dim, num_keys)\n",
    "    attentions_matrix = torch.bmm(q, k.transpose(1,2))             # (batch_size, 1, num_keys)\n",
    "    attention_probability = F.softmax(attentions_matrix, dim = 2)      # (batch_size, 1, num_keys)\n",
    "\n",
    "\n",
    "    output = torch.bmm(attention_probability,v)         # (batch_size, 1, embed_dim)\n",
    "    # print(\"o\",output.shape)\n",
    "    output = output.squeeze(1)                      # (batch_size, embed_dim)\n",
    "\n",
    "\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8pshjz9hRps"
   },
   "source": [
    "\n",
    "# Synthetic Data Set\n",
    "\n",
    "This is a synthetic dataset. One way to test a model during development is to take a small piece of data and show that you can overfit a model. If you can't overfit an easily learned chunk of data, then you probably have something wrong in your code. In this case I have provided a small chunk of synthetic data that should be easy to learn.\n",
    "\n",
    "- The vocabulary is 20 word: 5 names, 5 relations, 5 question-words, 5 values\n",
    " - First 5 elements of the vocab are names (for example index 0 might be \"Hamilton\").\n",
    " - Second 5 elements of the vocab are relations (for example, \"born\", \"died\", \"occupation\").\n",
    " - Third 5 elements are random words that might be part of a query (for example, \"When was\").\n",
    " - Final 5 elements of the vocab are possible values (for example, \"1757\")\n",
    "- A \"question\" is a name (5, 1), relation (5, 1), some words (5, 1), and no values\n",
    "- The keys will all have the same name (5, 5) where each row is idential, relations (5, 5), no words, no values\n",
    "- Values will have no names, no relations, no words, and value vocab words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "id": "Qvuyp-g7grYw"
   },
   "outputs": [],
   "source": [
    "# Turn on a different relation on each row\n",
    "relations = torch.zeros(5, 5)\n",
    "relations.fill_diagonal_(1)\n",
    "\n",
    "# training data\n",
    "train_data = {}\n",
    "for i in range(5):\n",
    "  # Name associated with questions, keys, values\n",
    "  train_data[i] = (torch.cat([F.one_hot(torch.arange(0, 5))[i].repeat(5, 1),\n",
    "                         relations,\n",
    "                         torch.randint(0, 2, (5, 5)).float(),\n",
    "                         torch.zeros(5, 5)], dim=1),\n",
    "              torch.cat([F.one_hot(torch.arange(0, 5))[i].repeat(5, 1),\n",
    "                         relations,\n",
    "                         torch.zeros(5, 5),\n",
    "                         torch.zeros(5, 5)], dim=1),\n",
    "              torch.cat([torch.zeros(5, 5),\n",
    "                         torch.zeros(5, 5),\n",
    "                         torch.zeros(5, 5),\n",
    "                         torch.randint(0, 2, (5, 5)).float()], dim=1))\n",
    "  Y = torch.cat([v[2] for v in list(train_data.values())], dim=0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 0\n",
      "Tensor 0 shape: torch.Size([5, 20])\n",
      "Tensor 1 shape: torch.Size([5, 20])\n",
      "Tensor 2 shape: torch.Size([5, 20])\n",
      "Key: 1\n",
      "Tensor 0 shape: torch.Size([5, 20])\n",
      "Tensor 1 shape: torch.Size([5, 20])\n",
      "Tensor 2 shape: torch.Size([5, 20])\n",
      "Key: 2\n",
      "Tensor 0 shape: torch.Size([5, 20])\n",
      "Tensor 1 shape: torch.Size([5, 20])\n",
      "Tensor 2 shape: torch.Size([5, 20])\n",
      "Key: 3\n",
      "Tensor 0 shape: torch.Size([5, 20])\n",
      "Tensor 1 shape: torch.Size([5, 20])\n",
      "Tensor 2 shape: torch.Size([5, 20])\n",
      "Key: 4\n",
      "Tensor 0 shape: torch.Size([5, 20])\n",
      "Tensor 1 shape: torch.Size([5, 20])\n",
      "Tensor 2 shape: torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "# VERIFY synthetic data shape\n",
    "train_data[1]\n",
    "for k, v in train_data.items():\n",
    "    print(f\"Key: {k}\")\n",
    "    for i, tensor in enumerate(v):\n",
    "        print(f\"Tensor {i} shape: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6R_xIi_TZVp"
   },
   "source": [
    "# Part C: Train on Synthetic Data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4slHUG5cPDtT"
   },
   "source": [
    "The following describes the steps to set up a training loop, including the training of the $B$ layer.\n",
    "\n",
    "![The KVMemNet being used in the training loop](https://github.com/markriedl/kvmemnet-assignment/blob/main/kvmemnet-outside.png?raw=true)\n",
    "\n",
    "- Create a model with the given vocabulary size and an embedding size that is equal to or smaller.\n",
    "- Loop through `N` epochs:\n",
    " - There are five names, loop through each name.\n",
    "   - Get a stack of questions, stack of keys, and stack of values from `DB_synth`.\n",
    "   - Loop through the relations. There is relation on each row of the keys and values.\n",
    "     - Get a single question, the `i`-th row in the questions pulled from `DB_synth` above.\n",
    "     - Compute the target: this is the `name*5 + i` element in `Y`.\n",
    "     - Run the singular question, stack of keys, and stack of values through the model and produce an output, which is a tensor of feature weights.\n",
    "     - Run all of `Y` through `model.B()` to get an embedded stack of values.\n",
    "     - Take the softmax of the inner product between the embedded stack of values from `Y` and the feature weight generated by the model.\n",
    "     - Compute the loss with `nn.CrossEntropyLoss`.\n",
    "     - Call `.backward()` on the loss.\n",
    "\n",
    "In addition to printing the loss (after every question or after every name in `DB_synth`) you can also print the target and the argmax of the softmax result to see if they match. Over time you should see the target and the argmax in agreement. For the purposes of this part of the project it is sufficient to test on the training set.\n",
    "\n",
    "Don't forget to move the model and the tensor to the GPU.\n",
    "\n",
    "You may want to speed up training by implementing batching. To do this, the model `forward()` needs to take tensors with an extra batching dimension as the first dimension. However, `.inner()`, `.mm()`, and `.matmul()` will not work properly. You will need to use `.bmm()` instead, which understands the first dimension is for batching. You will likely find that you need to perform some `.squeeze()` and `.unsqueeze()` operations. You can try batch-size of one, or take entire chunks (or even all synthetic data as a single, large batch). Try it different ways.\n",
    "\n",
    "Try training on the synthetic data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zu1CMkabZkyU"
   },
   "source": [
    "You may make as many cells as necessary. Save your notebook outputs that plot loss and show it reducing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MqIdFVAbqr1"
   },
   "source": [
    "**Write code blocks below that create the `KVMemNet`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "id": "wxso4hXaTKSK"
   },
   "outputs": [],
   "source": [
    "# Set up your KVMemNet, move it to the GPU, setup up optimizer (e.g., Adam), and criterion.\n",
    "\n",
    "# Init parameters\n",
    "vocab_size = 20  \n",
    "embed_dim = 5   # Embedding dimension\n",
    "num_names = 5\n",
    "num_relations = 5\n",
    "\n",
    "# Create the Key-Value Memory Network\n",
    "model = KVMemNet(vocab_size, embed_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up optimizer (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0008)\n",
    "\n",
    "# Set up loss criterion - CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "001D35pTb82K"
   },
   "source": [
    "**Write and run a training testing loop. Show that your training loop loss converges with a plot**\n",
    "\n",
    "To plot a loss curve, compute the mean loss per epoch and save it in a list:\n",
    "```\n",
    "x_axis.append(epoch_number)\n",
    "y_axis.append(mean_epoch_loss_for_this_epoch)\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "InBysHJfTTYX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  average loss = 3.2179 accuracy = 4.00%\n",
      "Epoch  2  average loss = 3.2159 accuracy = 4.00%\n",
      "Epoch  3  average loss = 3.2148 accuracy = 4.00%\n",
      "Epoch  4  average loss = 3.2137 accuracy = 4.00%\n",
      "Epoch  5  average loss = 3.2126 accuracy = 4.00%\n",
      "Epoch  6  average loss = 3.2114 accuracy = 4.00%\n",
      "Epoch  7  average loss = 3.2102 accuracy = 4.00%\n",
      "Epoch  8  average loss = 3.2090 accuracy = 4.00%\n",
      "Epoch  9  average loss = 3.2076 accuracy = 4.00%\n",
      "Epoch 10  average loss = 3.2062 accuracy = 4.00%\n",
      "Epoch 11  average loss = 3.2047 accuracy = 4.00%\n",
      "Epoch 12  average loss = 3.2031 accuracy = 4.00%\n",
      "Epoch 13  average loss = 3.2014 accuracy = 8.00%\n",
      "Epoch 14  average loss = 3.1995 accuracy = 8.00%\n",
      "Epoch 15  average loss = 3.1975 accuracy = 8.00%\n",
      "Epoch 16  average loss = 3.1953 accuracy = 8.00%\n",
      "Epoch 17  average loss = 3.1928 accuracy = 8.00%\n",
      "Epoch 18  average loss = 3.1901 accuracy = 8.00%\n",
      "Epoch 19  average loss = 3.1871 accuracy = 8.00%\n",
      "Epoch 20  average loss = 3.1838 accuracy = 8.00%\n",
      "Epoch 21  average loss = 3.1800 accuracy = 8.00%\n",
      "Epoch 22  average loss = 3.1758 accuracy = 8.00%\n",
      "Epoch 23  average loss = 3.1710 accuracy = 8.00%\n",
      "Epoch 24  average loss = 3.1656 accuracy = 8.00%\n",
      "Epoch 25  average loss = 3.1595 accuracy = 8.00%\n",
      "Epoch 26  average loss = 3.1526 accuracy = 8.00%\n",
      "Epoch 27  average loss = 3.1448 accuracy = 8.00%\n",
      "Epoch 28  average loss = 3.1361 accuracy = 8.00%\n",
      "Epoch 29  average loss = 3.1264 accuracy = 8.00%\n",
      "Epoch 30  average loss = 3.1155 accuracy = 12.00%\n",
      "Epoch 31  average loss = 3.1035 accuracy = 12.00%\n",
      "Epoch 32  average loss = 3.0902 accuracy = 20.00%\n",
      "Epoch 33  average loss = 3.0756 accuracy = 20.00%\n",
      "Epoch 34  average loss = 3.0596 accuracy = 24.00%\n",
      "Epoch 35  average loss = 3.0420 accuracy = 28.00%\n",
      "Epoch 36  average loss = 3.0229 accuracy = 28.00%\n",
      "Epoch 37  average loss = 3.0022 accuracy = 28.00%\n",
      "Epoch 38  average loss = 2.9798 accuracy = 28.00%\n",
      "Epoch 39  average loss = 2.9556 accuracy = 28.00%\n",
      "Epoch 40  average loss = 2.9298 accuracy = 24.00%\n",
      "Epoch 41  average loss = 2.9023 accuracy = 24.00%\n",
      "Epoch 42  average loss = 2.8732 accuracy = 24.00%\n",
      "Epoch 43  average loss = 2.8426 accuracy = 24.00%\n",
      "Epoch 44  average loss = 2.8108 accuracy = 24.00%\n",
      "Epoch 45  average loss = 2.7778 accuracy = 24.00%\n",
      "Epoch 46  average loss = 2.7440 accuracy = 24.00%\n",
      "Epoch 47  average loss = 2.7096 accuracy = 24.00%\n",
      "Epoch 48  average loss = 2.6748 accuracy = 24.00%\n",
      "Epoch 49  average loss = 2.6399 accuracy = 24.00%\n",
      "Epoch 50  average loss = 2.6051 accuracy = 28.00%\n",
      "Epoch 51  average loss = 2.5705 accuracy = 32.00%\n",
      "Epoch 52  average loss = 2.5364 accuracy = 32.00%\n",
      "Epoch 53  average loss = 2.5027 accuracy = 32.00%\n",
      "Epoch 54  average loss = 2.4697 accuracy = 32.00%\n",
      "Epoch 55  average loss = 2.4374 accuracy = 32.00%\n",
      "Epoch 56  average loss = 2.4057 accuracy = 36.00%\n",
      "Epoch 57  average loss = 2.3748 accuracy = 36.00%\n",
      "Epoch 58  average loss = 2.3446 accuracy = 36.00%\n",
      "Epoch 59  average loss = 2.3151 accuracy = 36.00%\n",
      "Epoch 60  average loss = 2.2864 accuracy = 36.00%\n",
      "Epoch 61  average loss = 2.2583 accuracy = 36.00%\n",
      "Epoch 62  average loss = 2.2309 accuracy = 36.00%\n",
      "Epoch 63  average loss = 2.2042 accuracy = 40.00%\n",
      "Epoch 64  average loss = 2.1781 accuracy = 44.00%\n",
      "Epoch 65  average loss = 2.1527 accuracy = 44.00%\n",
      "Epoch 66  average loss = 2.1279 accuracy = 44.00%\n",
      "Epoch 67  average loss = 2.1037 accuracy = 48.00%\n",
      "Epoch 68  average loss = 2.0801 accuracy = 48.00%\n",
      "Epoch 69  average loss = 2.0571 accuracy = 48.00%\n",
      "Epoch 70  average loss = 2.0346 accuracy = 48.00%\n",
      "Epoch 71  average loss = 2.0127 accuracy = 48.00%\n",
      "Epoch 72  average loss = 1.9913 accuracy = 48.00%\n",
      "Epoch 73  average loss = 1.9704 accuracy = 48.00%\n",
      "Epoch 74  average loss = 1.9501 accuracy = 48.00%\n",
      "Epoch 75  average loss = 1.9302 accuracy = 48.00%\n",
      "Epoch 76  average loss = 1.9108 accuracy = 48.00%\n",
      "Epoch 77  average loss = 1.8919 accuracy = 48.00%\n",
      "Epoch 78  average loss = 1.8734 accuracy = 48.00%\n",
      "Epoch 79  average loss = 1.8554 accuracy = 48.00%\n",
      "Epoch 80  average loss = 1.8377 accuracy = 48.00%\n",
      "Epoch 81  average loss = 1.8205 accuracy = 48.00%\n",
      "Epoch 82  average loss = 1.8036 accuracy = 48.00%\n",
      "Epoch 83  average loss = 1.7871 accuracy = 48.00%\n",
      "Epoch 84  average loss = 1.7710 accuracy = 48.00%\n",
      "Epoch 85  average loss = 1.7552 accuracy = 48.00%\n",
      "Epoch 86  average loss = 1.7398 accuracy = 48.00%\n",
      "Epoch 87  average loss = 1.7247 accuracy = 48.00%\n",
      "Epoch 88  average loss = 1.7098 accuracy = 48.00%\n",
      "Epoch 89  average loss = 1.6953 accuracy = 48.00%\n",
      "Epoch 90  average loss = 1.6811 accuracy = 48.00%\n",
      "Epoch 91  average loss = 1.6671 accuracy = 48.00%\n",
      "Epoch 92  average loss = 1.6535 accuracy = 48.00%\n",
      "Epoch 93  average loss = 1.6400 accuracy = 48.00%\n",
      "Epoch 94  average loss = 1.6269 accuracy = 52.00%\n",
      "Epoch 95  average loss = 1.6139 accuracy = 52.00%\n",
      "Epoch 96  average loss = 1.6012 accuracy = 52.00%\n",
      "Epoch 97  average loss = 1.5888 accuracy = 52.00%\n",
      "Epoch 98  average loss = 1.5765 accuracy = 52.00%\n",
      "Epoch 99  average loss = 1.5645 accuracy = 52.00%\n",
      "Epoch 100  average loss = 1.5527 accuracy = 52.00%\n",
      "Epoch 101  average loss = 1.5410 accuracy = 52.00%\n",
      "Epoch 102  average loss = 1.5296 accuracy = 52.00%\n",
      "Epoch 103  average loss = 1.5184 accuracy = 52.00%\n",
      "Epoch 104  average loss = 1.5073 accuracy = 52.00%\n",
      "Epoch 105  average loss = 1.4965 accuracy = 52.00%\n",
      "Epoch 106  average loss = 1.4858 accuracy = 52.00%\n",
      "Epoch 107  average loss = 1.4752 accuracy = 52.00%\n",
      "Epoch 108  average loss = 1.4649 accuracy = 52.00%\n",
      "Epoch 109  average loss = 1.4547 accuracy = 52.00%\n",
      "Epoch 110  average loss = 1.4446 accuracy = 52.00%\n",
      "Epoch 111  average loss = 1.4347 accuracy = 52.00%\n",
      "Epoch 112  average loss = 1.4250 accuracy = 52.00%\n",
      "Epoch 113  average loss = 1.4154 accuracy = 52.00%\n",
      "Epoch 114  average loss = 1.4059 accuracy = 52.00%\n",
      "Epoch 115  average loss = 1.3966 accuracy = 52.00%\n",
      "Epoch 116  average loss = 1.3874 accuracy = 52.00%\n",
      "Epoch 117  average loss = 1.3783 accuracy = 52.00%\n",
      "Epoch 118  average loss = 1.3693 accuracy = 52.00%\n",
      "Epoch 119  average loss = 1.3605 accuracy = 52.00%\n",
      "Epoch 120  average loss = 1.3518 accuracy = 52.00%\n",
      "Epoch 121  average loss = 1.3432 accuracy = 52.00%\n",
      "Epoch 122  average loss = 1.3347 accuracy = 52.00%\n",
      "Epoch 123  average loss = 1.3263 accuracy = 52.00%\n",
      "Epoch 124  average loss = 1.3180 accuracy = 52.00%\n",
      "Epoch 125  average loss = 1.3098 accuracy = 52.00%\n",
      "Epoch 126  average loss = 1.3017 accuracy = 52.00%\n",
      "Epoch 127  average loss = 1.2937 accuracy = 52.00%\n",
      "Epoch 128  average loss = 1.2858 accuracy = 52.00%\n",
      "Epoch 129  average loss = 1.2780 accuracy = 52.00%\n",
      "Epoch 130  average loss = 1.2702 accuracy = 52.00%\n",
      "Epoch 131  average loss = 1.2626 accuracy = 56.00%\n",
      "Epoch 132  average loss = 1.2550 accuracy = 56.00%\n",
      "Epoch 133  average loss = 1.2475 accuracy = 56.00%\n",
      "Epoch 134  average loss = 1.2400 accuracy = 56.00%\n",
      "Epoch 135  average loss = 1.2327 accuracy = 56.00%\n",
      "Epoch 136  average loss = 1.2254 accuracy = 56.00%\n",
      "Epoch 137  average loss = 1.2182 accuracy = 56.00%\n",
      "Epoch 138  average loss = 1.2110 accuracy = 56.00%\n",
      "Epoch 139  average loss = 1.2039 accuracy = 56.00%\n",
      "Epoch 140  average loss = 1.1969 accuracy = 56.00%\n",
      "Epoch 141  average loss = 1.1900 accuracy = 56.00%\n",
      "Epoch 142  average loss = 1.1830 accuracy = 56.00%\n",
      "Epoch 143  average loss = 1.1762 accuracy = 56.00%\n",
      "Epoch 144  average loss = 1.1694 accuracy = 56.00%\n",
      "Epoch 145  average loss = 1.1627 accuracy = 56.00%\n",
      "Epoch 146  average loss = 1.1560 accuracy = 56.00%\n",
      "Epoch 147  average loss = 1.1493 accuracy = 56.00%\n",
      "Epoch 148  average loss = 1.1427 accuracy = 60.00%\n",
      "Epoch 149  average loss = 1.1362 accuracy = 60.00%\n",
      "Epoch 150  average loss = 1.1297 accuracy = 60.00%\n",
      "Epoch 151  average loss = 1.1232 accuracy = 60.00%\n",
      "Epoch 152  average loss = 1.1168 accuracy = 60.00%\n",
      "Epoch 153  average loss = 1.1105 accuracy = 60.00%\n",
      "Epoch 154  average loss = 1.1041 accuracy = 60.00%\n",
      "Epoch 155  average loss = 1.0978 accuracy = 60.00%\n",
      "Epoch 156  average loss = 1.0916 accuracy = 60.00%\n",
      "Epoch 157  average loss = 1.0854 accuracy = 60.00%\n",
      "Epoch 158  average loss = 1.0792 accuracy = 60.00%\n",
      "Epoch 159  average loss = 1.0730 accuracy = 64.00%\n",
      "Epoch 160  average loss = 1.0669 accuracy = 64.00%\n",
      "Epoch 161  average loss = 1.0608 accuracy = 64.00%\n",
      "Epoch 162  average loss = 1.0548 accuracy = 64.00%\n",
      "Epoch 163  average loss = 1.0488 accuracy = 64.00%\n",
      "Epoch 164  average loss = 1.0428 accuracy = 64.00%\n",
      "Epoch 165  average loss = 1.0368 accuracy = 64.00%\n",
      "Epoch 166  average loss = 1.0309 accuracy = 64.00%\n",
      "Epoch 167  average loss = 1.0250 accuracy = 64.00%\n",
      "Epoch 168  average loss = 1.0191 accuracy = 64.00%\n",
      "Epoch 169  average loss = 1.0133 accuracy = 64.00%\n",
      "Epoch 170  average loss = 1.0074 accuracy = 64.00%\n",
      "Epoch 171  average loss = 1.0016 accuracy = 64.00%\n",
      "Epoch 172  average loss = 0.9959 accuracy = 64.00%\n",
      "Epoch 173  average loss = 0.9901 accuracy = 64.00%\n",
      "Epoch 174  average loss = 0.9844 accuracy = 64.00%\n",
      "Epoch 175  average loss = 0.9787 accuracy = 64.00%\n",
      "Epoch 176  average loss = 0.9731 accuracy = 64.00%\n",
      "Epoch 177  average loss = 0.9674 accuracy = 64.00%\n",
      "Epoch 178  average loss = 0.9618 accuracy = 64.00%\n",
      "Epoch 179  average loss = 0.9562 accuracy = 64.00%\n",
      "Epoch 180  average loss = 0.9506 accuracy = 64.00%\n",
      "Epoch 181  average loss = 0.9451 accuracy = 64.00%\n",
      "Epoch 182  average loss = 0.9396 accuracy = 64.00%\n",
      "Epoch 183  average loss = 0.9341 accuracy = 64.00%\n",
      "Epoch 184  average loss = 0.9286 accuracy = 64.00%\n",
      "Epoch 185  average loss = 0.9232 accuracy = 68.00%\n",
      "Epoch 186  average loss = 0.9178 accuracy = 68.00%\n",
      "Epoch 187  average loss = 0.9124 accuracy = 68.00%\n",
      "Epoch 188  average loss = 0.9070 accuracy = 68.00%\n",
      "Epoch 189  average loss = 0.9017 accuracy = 68.00%\n",
      "Epoch 190  average loss = 0.8964 accuracy = 68.00%\n",
      "Epoch 191  average loss = 0.8911 accuracy = 68.00%\n",
      "Epoch 192  average loss = 0.8859 accuracy = 68.00%\n",
      "Epoch 193  average loss = 0.8807 accuracy = 68.00%\n",
      "Epoch 194  average loss = 0.8755 accuracy = 68.00%\n",
      "Epoch 195  average loss = 0.8704 accuracy = 68.00%\n",
      "Epoch 196  average loss = 0.8653 accuracy = 68.00%\n",
      "Epoch 197  average loss = 0.8602 accuracy = 68.00%\n",
      "Epoch 198  average loss = 0.8551 accuracy = 68.00%\n",
      "Epoch 199  average loss = 0.8501 accuracy = 68.00%\n",
      "Epoch 200  average loss = 0.8451 accuracy = 68.00%\n",
      "Epoch 201  average loss = 0.8402 accuracy = 68.00%\n",
      "Epoch 202  average loss = 0.8353 accuracy = 68.00%\n",
      "Epoch 203  average loss = 0.8304 accuracy = 68.00%\n",
      "Epoch 204  average loss = 0.8256 accuracy = 68.00%\n",
      "Epoch 205  average loss = 0.8208 accuracy = 68.00%\n",
      "Epoch 206  average loss = 0.8160 accuracy = 68.00%\n",
      "Epoch 207  average loss = 0.8113 accuracy = 68.00%\n",
      "Epoch 208  average loss = 0.8066 accuracy = 68.00%\n",
      "Epoch 209  average loss = 0.8019 accuracy = 68.00%\n",
      "Epoch 210  average loss = 0.7973 accuracy = 68.00%\n",
      "Epoch 211  average loss = 0.7928 accuracy = 68.00%\n",
      "Epoch 212  average loss = 0.7882 accuracy = 68.00%\n",
      "Epoch 213  average loss = 0.7837 accuracy = 68.00%\n",
      "Epoch 214  average loss = 0.7793 accuracy = 68.00%\n",
      "Epoch 215  average loss = 0.7749 accuracy = 68.00%\n",
      "Epoch 216  average loss = 0.7705 accuracy = 68.00%\n",
      "Epoch 217  average loss = 0.7662 accuracy = 72.00%\n",
      "Epoch 218  average loss = 0.7619 accuracy = 72.00%\n",
      "Epoch 219  average loss = 0.7577 accuracy = 72.00%\n",
      "Epoch 220  average loss = 0.7535 accuracy = 72.00%\n",
      "Epoch 221  average loss = 0.7493 accuracy = 72.00%\n",
      "Epoch 222  average loss = 0.7452 accuracy = 72.00%\n",
      "Epoch 223  average loss = 0.7411 accuracy = 72.00%\n",
      "Epoch 224  average loss = 0.7371 accuracy = 72.00%\n",
      "Epoch 225  average loss = 0.7331 accuracy = 72.00%\n",
      "Epoch 226  average loss = 0.7291 accuracy = 72.00%\n",
      "Epoch 227  average loss = 0.7252 accuracy = 72.00%\n",
      "Epoch 228  average loss = 0.7214 accuracy = 72.00%\n",
      "Epoch 229  average loss = 0.7176 accuracy = 72.00%\n",
      "Epoch 230  average loss = 0.7138 accuracy = 72.00%\n",
      "Epoch 231  average loss = 0.7101 accuracy = 72.00%\n",
      "Epoch 232  average loss = 0.7064 accuracy = 72.00%\n",
      "Epoch 233  average loss = 0.7027 accuracy = 72.00%\n",
      "Epoch 234  average loss = 0.6991 accuracy = 72.00%\n",
      "Epoch 235  average loss = 0.6955 accuracy = 72.00%\n",
      "Epoch 236  average loss = 0.6920 accuracy = 72.00%\n",
      "Epoch 237  average loss = 0.6885 accuracy = 72.00%\n",
      "Epoch 238  average loss = 0.6851 accuracy = 72.00%\n",
      "Epoch 239  average loss = 0.6817 accuracy = 72.00%\n",
      "Epoch 240  average loss = 0.6784 accuracy = 72.00%\n",
      "Epoch 241  average loss = 0.6751 accuracy = 72.00%\n",
      "Epoch 242  average loss = 0.6718 accuracy = 72.00%\n",
      "Epoch 243  average loss = 0.6685 accuracy = 72.00%\n",
      "Epoch 244  average loss = 0.6654 accuracy = 72.00%\n",
      "Epoch 245  average loss = 0.6622 accuracy = 72.00%\n",
      "Epoch 246  average loss = 0.6591 accuracy = 72.00%\n",
      "Epoch 247  average loss = 0.6560 accuracy = 72.00%\n",
      "Epoch 248  average loss = 0.6530 accuracy = 72.00%\n",
      "Epoch 249  average loss = 0.6500 accuracy = 72.00%\n",
      "Epoch 250  average loss = 0.6470 accuracy = 72.00%\n",
      "Epoch 251  average loss = 0.6441 accuracy = 72.00%\n",
      "Epoch 252  average loss = 0.6412 accuracy = 72.00%\n",
      "Epoch 253  average loss = 0.6384 accuracy = 72.00%\n",
      "Epoch 254  average loss = 0.6356 accuracy = 72.00%\n",
      "Epoch 255  average loss = 0.6328 accuracy = 72.00%\n",
      "Epoch 256  average loss = 0.6301 accuracy = 72.00%\n",
      "Epoch 257  average loss = 0.6274 accuracy = 72.00%\n",
      "Epoch 258  average loss = 0.6248 accuracy = 72.00%\n",
      "Epoch 259  average loss = 0.6221 accuracy = 72.00%\n",
      "Epoch 260  average loss = 0.6195 accuracy = 72.00%\n",
      "Epoch 261  average loss = 0.6170 accuracy = 72.00%\n",
      "Epoch 262  average loss = 0.6145 accuracy = 72.00%\n",
      "Epoch 263  average loss = 0.6120 accuracy = 72.00%\n",
      "Epoch 264  average loss = 0.6095 accuracy = 72.00%\n",
      "Epoch 265  average loss = 0.6071 accuracy = 72.00%\n",
      "Epoch 266  average loss = 0.6047 accuracy = 72.00%\n",
      "Epoch 267  average loss = 0.6024 accuracy = 72.00%\n",
      "Epoch 268  average loss = 0.6001 accuracy = 72.00%\n",
      "Epoch 269  average loss = 0.5978 accuracy = 72.00%\n",
      "Epoch 270  average loss = 0.5955 accuracy = 72.00%\n",
      "Epoch 271  average loss = 0.5933 accuracy = 72.00%\n",
      "Epoch 272  average loss = 0.5911 accuracy = 72.00%\n",
      "Epoch 273  average loss = 0.5889 accuracy = 72.00%\n",
      "Epoch 274  average loss = 0.5868 accuracy = 72.00%\n",
      "Epoch 275  average loss = 0.5847 accuracy = 72.00%\n",
      "Epoch 276  average loss = 0.5826 accuracy = 72.00%\n",
      "Epoch 277  average loss = 0.5806 accuracy = 72.00%\n",
      "Epoch 278  average loss = 0.5786 accuracy = 72.00%\n",
      "Epoch 279  average loss = 0.5766 accuracy = 72.00%\n",
      "Epoch 280  average loss = 0.5746 accuracy = 72.00%\n",
      "Epoch 281  average loss = 0.5727 accuracy = 72.00%\n",
      "Epoch 282  average loss = 0.5708 accuracy = 72.00%\n",
      "Epoch 283  average loss = 0.5689 accuracy = 72.00%\n",
      "Epoch 284  average loss = 0.5670 accuracy = 72.00%\n",
      "Epoch 285  average loss = 0.5652 accuracy = 72.00%\n",
      "Epoch 286  average loss = 0.5634 accuracy = 72.00%\n",
      "Epoch 287  average loss = 0.5616 accuracy = 72.00%\n",
      "Epoch 288  average loss = 0.5598 accuracy = 72.00%\n",
      "Epoch 289  average loss = 0.5581 accuracy = 72.00%\n",
      "Epoch 290  average loss = 0.5564 accuracy = 72.00%\n",
      "Epoch 291  average loss = 0.5547 accuracy = 72.00%\n",
      "Epoch 292  average loss = 0.5531 accuracy = 72.00%\n",
      "Epoch 293  average loss = 0.5514 accuracy = 72.00%\n",
      "Epoch 294  average loss = 0.5498 accuracy = 72.00%\n",
      "Epoch 295  average loss = 0.5482 accuracy = 72.00%\n",
      "Epoch 296  average loss = 0.5466 accuracy = 72.00%\n",
      "Epoch 297  average loss = 0.5451 accuracy = 72.00%\n",
      "Epoch 298  average loss = 0.5436 accuracy = 72.00%\n",
      "Epoch 299  average loss = 0.5421 accuracy = 72.00%\n",
      "Epoch 300  average loss = 0.5406 accuracy = 72.00%\n",
      "Epoch 301  average loss = 0.5391 accuracy = 72.00%\n",
      "Epoch 302  average loss = 0.5377 accuracy = 72.00%\n",
      "Epoch 303  average loss = 0.5362 accuracy = 72.00%\n",
      "Epoch 304  average loss = 0.5348 accuracy = 72.00%\n",
      "Epoch 305  average loss = 0.5335 accuracy = 72.00%\n",
      "Epoch 306  average loss = 0.5321 accuracy = 72.00%\n",
      "Epoch 307  average loss = 0.5307 accuracy = 72.00%\n",
      "Epoch 308  average loss = 0.5294 accuracy = 72.00%\n",
      "Epoch 309  average loss = 0.5281 accuracy = 72.00%\n",
      "Epoch 310  average loss = 0.5268 accuracy = 72.00%\n",
      "Epoch 311  average loss = 0.5255 accuracy = 72.00%\n",
      "Epoch 312  average loss = 0.5243 accuracy = 72.00%\n",
      "Epoch 313  average loss = 0.5230 accuracy = 72.00%\n",
      "Epoch 314  average loss = 0.5218 accuracy = 72.00%\n",
      "Epoch 315  average loss = 0.5206 accuracy = 72.00%\n",
      "Epoch 316  average loss = 0.5194 accuracy = 72.00%\n",
      "Epoch 317  average loss = 0.5182 accuracy = 72.00%\n",
      "Epoch 318  average loss = 0.5171 accuracy = 72.00%\n",
      "Epoch 319  average loss = 0.5159 accuracy = 72.00%\n",
      "Epoch 320  average loss = 0.5148 accuracy = 72.00%\n",
      "Epoch 321  average loss = 0.5137 accuracy = 72.00%\n",
      "Epoch 322  average loss = 0.5126 accuracy = 72.00%\n",
      "Epoch 323  average loss = 0.5115 accuracy = 72.00%\n",
      "Epoch 324  average loss = 0.5105 accuracy = 72.00%\n",
      "Epoch 325  average loss = 0.5094 accuracy = 72.00%\n",
      "Epoch 326  average loss = 0.5084 accuracy = 72.00%\n",
      "Epoch 327  average loss = 0.5074 accuracy = 72.00%\n",
      "Epoch 328  average loss = 0.5064 accuracy = 72.00%\n",
      "Epoch 329  average loss = 0.5054 accuracy = 72.00%\n",
      "Epoch 330  average loss = 0.5044 accuracy = 72.00%\n",
      "Epoch 331  average loss = 0.5034 accuracy = 72.00%\n",
      "Epoch 332  average loss = 0.5025 accuracy = 72.00%\n",
      "Epoch 333  average loss = 0.5015 accuracy = 72.00%\n",
      "Epoch 334  average loss = 0.5006 accuracy = 72.00%\n",
      "Epoch 335  average loss = 0.4997 accuracy = 72.00%\n",
      "Epoch 336  average loss = 0.4988 accuracy = 72.00%\n",
      "Epoch 337  average loss = 0.4979 accuracy = 72.00%\n",
      "Epoch 338  average loss = 0.4970 accuracy = 72.00%\n",
      "Epoch 339  average loss = 0.4961 accuracy = 72.00%\n",
      "Epoch 340  average loss = 0.4953 accuracy = 72.00%\n",
      "Epoch 341  average loss = 0.4944 accuracy = 72.00%\n",
      "Epoch 342  average loss = 0.4936 accuracy = 72.00%\n",
      "Epoch 343  average loss = 0.4928 accuracy = 72.00%\n",
      "Epoch 344  average loss = 0.4920 accuracy = 72.00%\n",
      "Epoch 345  average loss = 0.4912 accuracy = 72.00%\n",
      "Epoch 346  average loss = 0.4904 accuracy = 72.00%\n",
      "Epoch 347  average loss = 0.4896 accuracy = 72.00%\n",
      "Epoch 348  average loss = 0.4888 accuracy = 72.00%\n",
      "Epoch 349  average loss = 0.4881 accuracy = 72.00%\n",
      "Epoch 350  average loss = 0.4873 accuracy = 72.00%\n",
      "Epoch 351  average loss = 0.4866 accuracy = 72.00%\n",
      "Epoch 352  average loss = 0.4859 accuracy = 72.00%\n",
      "Epoch 353  average loss = 0.4851 accuracy = 72.00%\n",
      "Epoch 354  average loss = 0.4844 accuracy = 72.00%\n",
      "Epoch 355  average loss = 0.4837 accuracy = 72.00%\n",
      "Epoch 356  average loss = 0.4830 accuracy = 72.00%\n",
      "Epoch 357  average loss = 0.4824 accuracy = 72.00%\n",
      "Epoch 358  average loss = 0.4817 accuracy = 72.00%\n",
      "Epoch 359  average loss = 0.4810 accuracy = 72.00%\n",
      "Epoch 360  average loss = 0.4804 accuracy = 72.00%\n",
      "Epoch 361  average loss = 0.4797 accuracy = 72.00%\n",
      "Epoch 362  average loss = 0.4791 accuracy = 72.00%\n",
      "Epoch 363  average loss = 0.4785 accuracy = 72.00%\n",
      "Epoch 364  average loss = 0.4778 accuracy = 72.00%\n",
      "Epoch 365  average loss = 0.4772 accuracy = 72.00%\n",
      "Epoch 366  average loss = 0.4766 accuracy = 72.00%\n",
      "Epoch 367  average loss = 0.4760 accuracy = 72.00%\n",
      "Epoch 368  average loss = 0.4755 accuracy = 72.00%\n",
      "Epoch 369  average loss = 0.4749 accuracy = 72.00%\n",
      "Epoch 370  average loss = 0.4743 accuracy = 72.00%\n",
      "Epoch 371  average loss = 0.4737 accuracy = 72.00%\n",
      "Epoch 372  average loss = 0.4732 accuracy = 72.00%\n",
      "Epoch 373  average loss = 0.4726 accuracy = 72.00%\n",
      "Epoch 374  average loss = 0.4721 accuracy = 72.00%\n",
      "Epoch 375  average loss = 0.4716 accuracy = 72.00%\n",
      "Epoch 376  average loss = 0.4710 accuracy = 72.00%\n",
      "Epoch 377  average loss = 0.4705 accuracy = 72.00%\n",
      "Epoch 378  average loss = 0.4700 accuracy = 72.00%\n",
      "Epoch 379  average loss = 0.4695 accuracy = 72.00%\n",
      "Epoch 380  average loss = 0.4690 accuracy = 72.00%\n",
      "Epoch 381  average loss = 0.4685 accuracy = 72.00%\n",
      "Epoch 382  average loss = 0.4680 accuracy = 72.00%\n",
      "Epoch 383  average loss = 0.4675 accuracy = 72.00%\n",
      "Epoch 384  average loss = 0.4670 accuracy = 72.00%\n",
      "Epoch 385  average loss = 0.4666 accuracy = 72.00%\n",
      "Epoch 386  average loss = 0.4661 accuracy = 72.00%\n",
      "Epoch 387  average loss = 0.4657 accuracy = 72.00%\n",
      "Epoch 388  average loss = 0.4652 accuracy = 72.00%\n",
      "Epoch 389  average loss = 0.4648 accuracy = 72.00%\n",
      "Epoch 390  average loss = 0.4643 accuracy = 72.00%\n",
      "Epoch 391  average loss = 0.4639 accuracy = 72.00%\n",
      "Epoch 392  average loss = 0.4635 accuracy = 72.00%\n",
      "Epoch 393  average loss = 0.4630 accuracy = 72.00%\n",
      "Epoch 394  average loss = 0.4626 accuracy = 72.00%\n",
      "Epoch 395  average loss = 0.4622 accuracy = 72.00%\n",
      "Epoch 396  average loss = 0.4618 accuracy = 72.00%\n",
      "Epoch 397  average loss = 0.4614 accuracy = 72.00%\n",
      "Epoch 398  average loss = 0.4610 accuracy = 72.00%\n",
      "Epoch 399  average loss = 0.4606 accuracy = 72.00%\n",
      "Epoch 400  average loss = 0.4602 accuracy = 72.00%\n",
      "Epoch 401  average loss = 0.4599 accuracy = 72.00%\n",
      "Epoch 402  average loss = 0.4595 accuracy = 72.00%\n",
      "Epoch 403  average loss = 0.4591 accuracy = 72.00%\n",
      "Epoch 404  average loss = 0.4587 accuracy = 72.00%\n",
      "Epoch 405  average loss = 0.4584 accuracy = 72.00%\n",
      "Epoch 406  average loss = 0.4580 accuracy = 72.00%\n",
      "Epoch 407  average loss = 0.4577 accuracy = 72.00%\n",
      "Epoch 408  average loss = 0.4573 accuracy = 72.00%\n",
      "Epoch 409  average loss = 0.4570 accuracy = 72.00%\n",
      "Epoch 410  average loss = 0.4566 accuracy = 72.00%\n",
      "Epoch 411  average loss = 0.4563 accuracy = 72.00%\n",
      "Epoch 412  average loss = 0.4560 accuracy = 72.00%\n",
      "Epoch 413  average loss = 0.4557 accuracy = 72.00%\n",
      "Epoch 414  average loss = 0.4553 accuracy = 72.00%\n",
      "Epoch 415  average loss = 0.4550 accuracy = 72.00%\n",
      "Epoch 416  average loss = 0.4547 accuracy = 72.00%\n",
      "Epoch 417  average loss = 0.4544 accuracy = 72.00%\n",
      "Epoch 418  average loss = 0.4541 accuracy = 72.00%\n",
      "Epoch 419  average loss = 0.4538 accuracy = 72.00%\n",
      "Epoch 420  average loss = 0.4535 accuracy = 72.00%\n",
      "Epoch 421  average loss = 0.4532 accuracy = 72.00%\n",
      "Epoch 422  average loss = 0.4529 accuracy = 72.00%\n",
      "Epoch 423  average loss = 0.4526 accuracy = 72.00%\n",
      "Epoch 424  average loss = 0.4523 accuracy = 72.00%\n",
      "Epoch 425  average loss = 0.4521 accuracy = 72.00%\n",
      "Epoch 426  average loss = 0.4518 accuracy = 72.00%\n",
      "Epoch 427  average loss = 0.4515 accuracy = 72.00%\n",
      "Epoch 428  average loss = 0.4512 accuracy = 72.00%\n",
      "Epoch 429  average loss = 0.4510 accuracy = 72.00%\n",
      "Epoch 430  average loss = 0.4507 accuracy = 72.00%\n",
      "Epoch 431  average loss = 0.4505 accuracy = 72.00%\n",
      "Epoch 432  average loss = 0.4502 accuracy = 72.00%\n",
      "Epoch 433  average loss = 0.4500 accuracy = 72.00%\n",
      "Epoch 434  average loss = 0.4497 accuracy = 72.00%\n",
      "Epoch 435  average loss = 0.4495 accuracy = 72.00%\n",
      "Epoch 436  average loss = 0.4492 accuracy = 72.00%\n",
      "Epoch 437  average loss = 0.4490 accuracy = 72.00%\n",
      "Epoch 438  average loss = 0.4487 accuracy = 72.00%\n",
      "Epoch 439  average loss = 0.4485 accuracy = 72.00%\n",
      "Epoch 440  average loss = 0.4483 accuracy = 72.00%\n",
      "Epoch 441  average loss = 0.4481 accuracy = 72.00%\n",
      "Epoch 442  average loss = 0.4478 accuracy = 72.00%\n",
      "Epoch 443  average loss = 0.4476 accuracy = 72.00%\n",
      "Epoch 444  average loss = 0.4474 accuracy = 72.00%\n",
      "Epoch 445  average loss = 0.4472 accuracy = 72.00%\n",
      "Epoch 446  average loss = 0.4470 accuracy = 72.00%\n",
      "Epoch 447  average loss = 0.4467 accuracy = 72.00%\n",
      "Epoch 448  average loss = 0.4465 accuracy = 72.00%\n",
      "Epoch 449  average loss = 0.4463 accuracy = 72.00%\n",
      "Epoch 450  average loss = 0.4461 accuracy = 72.00%\n",
      "Epoch 451  average loss = 0.4459 accuracy = 72.00%\n",
      "Epoch 452  average loss = 0.4457 accuracy = 72.00%\n",
      "Epoch 453  average loss = 0.4455 accuracy = 72.00%\n",
      "Epoch 454  average loss = 0.4453 accuracy = 72.00%\n",
      "Epoch 455  average loss = 0.4452 accuracy = 72.00%\n",
      "Epoch 456  average loss = 0.4450 accuracy = 72.00%\n",
      "Epoch 457  average loss = 0.4448 accuracy = 72.00%\n",
      "Epoch 458  average loss = 0.4446 accuracy = 72.00%\n",
      "Epoch 459  average loss = 0.4444 accuracy = 72.00%\n",
      "Epoch 460  average loss = 0.4442 accuracy = 72.00%\n",
      "Epoch 461  average loss = 0.4441 accuracy = 72.00%\n",
      "Epoch 462  average loss = 0.4439 accuracy = 72.00%\n",
      "Epoch 463  average loss = 0.4437 accuracy = 72.00%\n",
      "Epoch 464  average loss = 0.4435 accuracy = 72.00%\n",
      "Epoch 465  average loss = 0.4434 accuracy = 72.00%\n",
      "Epoch 466  average loss = 0.4432 accuracy = 72.00%\n",
      "Epoch 467  average loss = 0.4430 accuracy = 72.00%\n",
      "Epoch 468  average loss = 0.4429 accuracy = 72.00%\n",
      "Epoch 469  average loss = 0.4427 accuracy = 72.00%\n",
      "Epoch 470  average loss = 0.4426 accuracy = 72.00%\n",
      "Epoch 471  average loss = 0.4424 accuracy = 72.00%\n",
      "Epoch 472  average loss = 0.4423 accuracy = 72.00%\n",
      "Epoch 473  average loss = 0.4421 accuracy = 72.00%\n",
      "Epoch 474  average loss = 0.4420 accuracy = 72.00%\n",
      "Epoch 475  average loss = 0.4418 accuracy = 72.00%\n",
      "Epoch 476  average loss = 0.4417 accuracy = 72.00%\n",
      "Epoch 477  average loss = 0.4415 accuracy = 72.00%\n",
      "Epoch 478  average loss = 0.4414 accuracy = 72.00%\n",
      "Epoch 479  average loss = 0.4412 accuracy = 72.00%\n",
      "Epoch 480  average loss = 0.4411 accuracy = 72.00%\n",
      "Epoch 481  average loss = 0.4410 accuracy = 72.00%\n",
      "Epoch 482  average loss = 0.4408 accuracy = 72.00%\n",
      "Epoch 483  average loss = 0.4407 accuracy = 72.00%\n",
      "Epoch 484  average loss = 0.4406 accuracy = 72.00%\n",
      "Epoch 485  average loss = 0.4404 accuracy = 72.00%\n",
      "Epoch 486  average loss = 0.4403 accuracy = 72.00%\n",
      "Epoch 487  average loss = 0.4402 accuracy = 72.00%\n",
      "Epoch 488  average loss = 0.4400 accuracy = 72.00%\n",
      "Epoch 489  average loss = 0.4399 accuracy = 72.00%\n",
      "Epoch 490  average loss = 0.4398 accuracy = 72.00%\n",
      "Epoch 491  average loss = 0.4397 accuracy = 72.00%\n",
      "Epoch 492  average loss = 0.4396 accuracy = 72.00%\n",
      "Epoch 493  average loss = 0.4394 accuracy = 72.00%\n",
      "Epoch 494  average loss = 0.4393 accuracy = 72.00%\n",
      "Epoch 495  average loss = 0.4392 accuracy = 72.00%\n",
      "Epoch 496  average loss = 0.4391 accuracy = 72.00%\n",
      "Epoch 497  average loss = 0.4390 accuracy = 72.00%\n",
      "Epoch 498  average loss = 0.4389 accuracy = 72.00%\n",
      "Epoch 499  average loss = 0.4388 accuracy = 72.00%\n",
      "Epoch 500  average loss = 0.4387 accuracy = 72.00%\n"
     ]
    }
   ],
   "source": [
    "# Write your training loop here\n",
    "# We stick to the picture above to set up part C\n",
    "\n",
    "x_axis, y_axis = [], []\n",
    "# Set up epoch\n",
    "epochs= 500\n",
    "\n",
    "# Iterate\n",
    "for epoch in range(epochs):\n",
    "    # Init record keeping\n",
    "    loss_count = 0\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    # Loop over names and extract train data\n",
    "    for name_id in range(num_names):\n",
    "        questions, keys, values = train_data[name_id]\n",
    "        questions = questions.to(device)\n",
    "        keys = keys.to(device)\n",
    "        values = values.to(device)\n",
    "\n",
    "        # Loop over relations\n",
    "        for relation_index in range(num_relations):\n",
    "            q = questions[relation_index].clone()          # (20)\n",
    "            k = keys.clone()                                # (5,20)\n",
    "            v = values.clone()                              # (5,20)\n",
    "            # print(\"q\",q.shape)\n",
    "            # print(\"k\",k.shape)\n",
    "            # print(\"v\",v.shape)\n",
    "\n",
    "            # Run forward pass\n",
    "            output = model(q, k, v)  # (1, embed_dim)\n",
    "            # print(output.shape)\n",
    "\n",
    "            # Embed all possible values using B\n",
    "            y_embed = model.B(Y)  # (25, embed_dim)\n",
    "\n",
    "            # Compute similarity and loss\n",
    "            pred_probability = torch.matmul(output, y_embed.T)  # (1, 25)\n",
    "            target = torch.tensor([name_id * num_relations + relation_index], dtype=torch.long).to(device)\n",
    "            # print(target.shape)\n",
    "\n",
    "            # Back Propagation\n",
    "            loss = criterion(pred_probability, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Increment recording tracking\n",
    "            loss_count += loss.item()\n",
    "            total_count += 1\n",
    "            pred = torch.argmax(pred_probability, dim=1).item()\n",
    "            # print(\"Target: \",target.item())\n",
    "            # print(\"Pred: \", pred)\n",
    "            correct_count += int(pred == target.item())\n",
    "    \n",
    "    accuracy = correct_count / total_count\n",
    "    avg_loss = loss_count / total_count\n",
    "    x_axis.append(epoch)\n",
    "    y_axis.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1:>2}  average loss = {avg_loss:.4f} accuracy = {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABH2UlEQVR4nO3dCZxN9f/H8c+YGfuSyK4oslPWUKlsIaVfaZEfRZIkssVPiyVRibSRpfz+WUqK/ESRLMlOCkWbQvaybzFz/o/PV/e6986d5c7c9ZzX8/G4Zu65Z86c+51r7nu+38/3e+Isy7IEAADAJrJF+gQAAACCiXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAABshXADAGHw22+/SVxcnIwaNSos3++mm24yN8CJCDdwlClTppg3mPXr10ss2LRpk7Rv315Kly4tOXLkkEsvvVSaNGki7777riQlJUX69KLa5s2b5e6775YrrrhCcubMKSVLlpSmTZvK66+/HtLvO3/+fBk8eLCEw/fff2++lwanUNKQpP9v9JYtWzbJnz+/VKhQQf7973/LokWLsnTst956y/y/BIIpIahHAxA0kyZNkkcffVSKFi1q3kTKly8vx48fl8WLF0vnzp1l79698p///CfSpxmVVq5cKTfffLNcfvnl0qVLFylWrJjs2rVLVq9eLWPHjpUePXqENNy8+eabYQk4Gm6GDBliwkeZMmW8Hlu4cGFQv1epUqVkxIgR5vOTJ0/Kzz//LB9//LFMnTpV7rnnHvMxMTExU+GmcOHC8uCDDwb1fOFshBsgCumbsAab+vXrmzfLfPnyuR/r1auX6XnasmVLUL6XvlHlyZNH7GT48OFSoEABWbdunVxyySVejx04cECcIHv27EE9nran9iJ6GjlypDzxxBMmoGi4evHFF4P6PYHMYlgK8OObb76RFi1amO73vHnzSuPGjU3g8HTu3DnzV7P2qOiwR6FCheT666/36qbft2+fPPTQQ+avXh1WKl68uNxxxx3pDiPocXUIYNq0aV7BxqV27druv3SXLl1q9tWP/mo8PLv89Wv0+fzyyy/SsmVLc+wHHnhAHn/8cbP91KlTKb7X/fffb3o+PIfBFixYIDfccIMJRXqMVq1aydatWzPUtr/++qu0bdvWDLHlzp1brrvuOvn000+99nE9p5kzZ5qgou2nbaw/B+0xSI8+vypVqqQINqpIkSLuzxs1aiQ1atTwewwddmnevHmKepkJEybIVVddZX6ederUMQHKs32110a5hnH05iutY7hs27bNDKtpO+lz15/53Llz3Y/rz1XbUWkvlet7uV4H/mpuzpw5Y3qUrr76anNMfT3+61//Mu2VGfHx8fLaa69J5cqV5Y033pCjR4+6H9Oh01tuucW0tz5P3WfcuHFeX6+BSF83y5Ytc5+/65z/+usv6du3r1SrVs28NvX/ov6f/PbbbzN1rnAWem4AH/rLVt+49Zdp//79TVf722+/bX7p6i/hevXqmf30TUK76R9++GGpW7euHDt2zPSobNy40dR2qLvuusscT4dB9Be59hpo+Nm5c2eKYQQXDRg69HTjjTeaYZVgO3/+vHnT1iCmb9YaMPRc9E1ZQ4brDdN1Lv/73//Mm7a+kan33ntPOnbsaI6hf6nrPvqmpcfTUJja81L79++XBg0amK/Rv/g1EP73v/+V22+/XWbNmiV33nlnip4BrfHQNzl943zppZdMGFuzZk2az1HrbFatWmV6t6pWrZrqfjrcp8NWvvtp2Pjxxx/l6aef9tp/+vTpZmiwa9eu5o1Yz0fDgQY2fZ3o9j179pifsbaTP+kdQ+lrpmHDhqZOaMCAASZEatBr06aNfPTRR6ad9PWhbajhQocnK1WqZL7W9dGXhtPbbrvNvLbuu+8+6dmzpzkPPVd9/hq2MkNfFxqAn3nmGVmxYoUJukpfExow9WebkJBgXkePPfaYJCcnS/fu3c0+r776qvm/oeFl0KBBZpsOwyptjzlz5pjXY9myZc1rR/8faiDV4bgSJUpk6nzhEBbgIO+++66lL/t169aluk+bNm2s7NmzW7/88ot72549e6x8+fJZN954o3tbjRo1rFatWqV6nMOHD5vv9fLLLwd0jt9++635up49e2Zo/yVLlpj99aOnHTt2mO36nF06duxotg0YMMBr3+TkZKtkyZLWXXfd5bV95syZZv/ly5eb+8ePH7cuueQSq0uXLl777du3zypQoECK7b569epljvfVV1+5t+kxy5Yta5UpU8ZKSkryek6VKlWyzp4969537NixZvvmzZvT/D4LFy604uPjza1+/fpW//79rc8//9z6+++/vfY7cuSIlTNnTuupp57y2v7EE09YefLksU6cOOHVloUKFbL++usv936ffPKJ2f6///3Pva179+5mm69AjtG4cWOrWrVq1pkzZ7x+Rg0aNLDKly/v3vbhhx/6/dmrRo0amZvLO++8Y/YdPXp0in312GnR41SpUiXVx2fPnm2OrT8fl1OnTqXYr3nz5taVV17ptU2P63meLvrcXa8HzzbMkSOHNXTo0DTPF2BYCvD561YLMfUv5CuvvNK9Xbvv27VrZ/4y1R4apUMe+hf2Tz/95PdYuXLlMnUPOkxw+PDhDJ+D6/j+hqOCpVu3bl73tQdB/0LW+p4TJ064t3/wwQem90B7ZZT+lX/kyBHzl/qhQ4fcN/3rXXu0lixZkub31eNrL5freEr/an/kkUfM0I/+Re5Jh/Q8a0e0R831V31atOdMe26010CHMbR3RHua9Ll4Du1oHYkOE86YMUPTiPs1oM9bXwO+tUj33nuvFCxYMODzCeQYOhzz5ZdfmiJd7VlxtfGff/5pnoO+3v744w8JlPb4aOGuv2Jqf0NngdCfodLz9Xz9u2ivmz4H7XXR5+k5fJUaHcrSXjvXz0Sfv34fHS7U3lEgLYQbwMPBgwfNkIn+AvWl3f3apa6zbtTQoUPNG73WL2hdQL9+/eS7777z+uWswzZan6Jd7TqMoG+yWoeTFh0O832jCCYdItAaFn9vuqdPn3a/+WvI0TCiocf15ucKclpLcdlll3ndNBSmV6z7+++/p9q2rsc9+Q7LuUJBRsKi1rLobB7dd+3atTJw4EDTplrH4hmiOnToYIYJv/rqK3P/iy++MEMgOmTlKyvnk9FjaE2RBi0d5vFt4+eeey7TRdFaV6Ntrz//YHMFYs9A/vXXX5tlCzQg6h8Cev6u2X0ZCTf6f23MmDGmpk3/L2kw02Po/7GMfD2cjZobIJM0rOgbxieffGLe2HXqtv4yHj9+vKnDcc1sat26takd+Pzzz80bltbp6F/m1157rd/jlitXzrwB6TotGZHaX92prYPj+RexJy3s1XoZre3QXiqtkdCwo6HH8w1HaT2JFhn7CvYbp6vOx5erlyUjtOdHg47eNIhqb9CHH37oDgraG6LhU6cy689UP+pz0zfmUJxPesdwtbHWGbkKmv29RqKJa+ae67z0/4UWf1esWFFGjx5t1mnSn4OGZf0/4nqOaXnhhRfM/5dOnTrJsGHDTGG1vm71/1RGvh7ORrgBPOhfhlpgu337dr+zV/SXq/6idtFfuPpmqTf961XfHLXQ2BVulBZq9unTx9y05+Oaa66RV155xbyJ+qPfX3tGNABpL5Hn9/PH9Ze/9iJ58u0FyQgdCtF1YHRoTIdmNOxo6PF8LkpnwPh780+PFvqm1raux0NJZxwpXSPIM2xomNPZR9rTpkFUi4xTCyHpyeoQj2s4VIuL02vjQL6X/uy0EFtn+WVmPZrUaIjWIml93bqGGzUYnz171vQCevZU+Ru2TO05aIG5zgKbPHmy13Z9nWsvDpAWhqUAD/qG1qxZM9Mb4zldW4cp9Be4/vJ2DRtpDYAnrQfQv1z1l7rS4S2deuv7BqNd9659UqO9CvqXvA6NeNbAuGzYsMHMMnIFAj3v5cuXe+2ja48ESntp9Nz02J999pkJO560J0Gfv/5VrW+S/ob10qLTz3WISOthPNfZ0anRGqR0unAw6Juov94U7TlQvkNj2s46LKQzmLS9fddzCYSrTsc3bGaUBkedmaczgzxDmL82DuR76cw9rXvRKdtZ6XnyDTY6Y+uHH34wH13/N1zB0PO4OpSk08N96XPwd/56DN/z0h63zNQbwXnouYEjvfPOO+bN25dOj33++edN4awGGZ26qkMt+kajb/paM+Oib8T6JlSrVi3Tg6PTwPWvTV0zRulUYu2a14Cg++pxZs+ebYKSTsVNi06X1qnZ+v21a99zhWItUNa/iPU8XUWxWhejlxXQv4I1QM2bNy9TdRk1a9Y0AU2n5erz9RySUvrmpVN89Xx0X30e2tulNSs6jVynL/t783TRac1avKvrleibobabBqkdO3aYgld/w2WZoUWzGi51yrS2399//21WLXb1RmlPmycdItSp4PrmqfU/+twyS18PSp+fhkF9k07v5+1Lf/b6+tNaLu1F0t4cfd1oKNy9e7d7rRftBdTja4+ThgcdcnStLeNLa4v+7//+T3r37m0CphYya7DUGiN9nWlhdVr0+K7eRm1b1wrFOgSlz0+Hjlz0DwQdhtIhWVdgnDhxojkv38Cm7aWvKX0962tP99HnoNPWta5Nf1b6/0GHaXXdJ89CfyBVkZ6uBURiKnhqt127dpn9Nm7caKat5s2b18qdO7d18803WytXrvQ61vPPP2/VrVvXTI3OlSuXVbFiRWv48OHu6caHDh0y04J1u04r1qnS9erVM9OrM2rDhg1Wu3btrBIlSliJiYlWwYIFzTTh//73v17TZA8ePGimceu56j5du3a1tmzZ4ncquJ5LWgYNGmS+rly5cqnuo1OPtX30OelU6quuusp68MEHrfXr16f7nHSK/d13323aTb9W23DevHkpjq/noFOd05ve7s+CBQusTp06mbbXn6FO7dfn06NHD2v//v1+v+all14yx37hhRdSPOb6vv6m9ev25557zn3//Pnz5vtcdtllVlxcnHtaeCDHcLVThw4drGLFipmfvU7Vv+2226xZs2Z57Tdx4kQzvVqnvXtOC/edCu6anq0/X516r8fUY+vPwnPZA3/0OJ7/T7RNdUp6+/btzbR7f+bOnWtVr17d/Ix1mv+LL77ono6ubeG5jIAuqaBLLehjrnPWqeB9+vSxihcvbv5/NWzY0Fq1apXf5wX4itN/Uo8+AOAMWmv05JNPmuHIUCyeCCB8CDcAHE9/DeplGHTF5PTW6gEQ/ai5AeBYWnOi9UsaaLSmQwvJAcQ+em4AOJYOQel1i3SROS2q1Yt0Aoh9hBsAAGArrHMDAABshXADAABsxXEFxXpNkj179phVYrO6TDoAAAgPraLRhUxLlCiR7oKfjgs3GmzSu1YPAACITnrNvVKlSqW5j+PCjfbYuBrHdR2UYNFr7ejVoXXp8WBemA7eaOfwoa3Dg3YOD9o5tttaL+irnROu9/G0OC7cuIaiNNiEItzolXH1uPzHCR3aOXxo6/CgncODdrZHW2ekpISCYgAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuEGwAAYCuOu7ZUSO3eLSVWrJC4nTtFEhJEChUSadBAJJ2rlwIAgOAh3ATLxImS0LWr1LGslI+1aydy/fUXPifwAAAQUoSbYNi9W6RrV4nzF2zU9OkXbr6Bp0oVkTNnRFq3FqlTJyynCgCA3RFuguGnn0RSCzap8Qw7w4aJ1Ksn0rs3vToAAGQRBcXBUL68SFxc1o6xZo3IvfeKlC5teoFMbxAAAAgY4SYYtKdl4kSxshpwXCZMIOQAAJBJhJtg6dxZzv/yi6zt21eStJ4mGEGHkAMAQMCouQmmUqVk7/XXS3LLlhL/4osiq1aJ/Pnnxce//lpk2rTA63M05OjtpZdE+vUL+mkDAGAnhJtQDlW1beu97dFHRUaMuBh6Fi0S+fjjjB+zf/8LPUJ9+wb9dAEAsAuGpSIVejTofPSRyK5dIjNnirRvn7Gv154bhqgAAEgV4SZaws57710IOhp60jNwYDjODACAmES4ibagM25c+iFn6lSRp58O55kBABAzCDfRHHLWrk19n+HDCTgAAPhBuIlmekkGnSGVVsAZNSqcZwQAQNQj3EQ7LSAeNCjtGVQUGAMA4Ea4iQXPP596wNE1c/RxAABgEG7sEHDefpvhKQAA/kG4ibWAo5di8IfhKQAADMJNrNEZUv6uW6XDU2PHRuKMAACIKoSbWJwmrtet8mf0aHpvAACOR7iJ1RlU/oankpPpvQEAOB7hxm7DU/TeAAAcjnATy8NTffqk3E7vDQDA4Qg3saxnT/+9N2PG0HsDAHAswo0de2+SkkR+/jkSZwQAgLPDzbhx46R69eqSP39+c6tfv74sWLAgza/58MMPpWLFipIzZ06pVq2azJ8/Xxztnnv8b8+TJ9xnAgBAVIhouClVqpSMHDlSNmzYIOvXr5dbbrlF7rjjDtm6davf/VeuXCn333+/dO7cWb755htp06aNuW3ZsiXs5x41Tpzwv/3kyXCfCQAAUSGi4aZ169bSsmVLKV++vFx99dUyfPhwyZs3r6xevdrv/mPHjpVbb71V+vXrJ5UqVZJhw4ZJzZo15Y033hDHKl9eJJufH+P69ZE4GwAAIi5BokRSUpIZcjp58qQZnvJn1apV0rt3b69tzZs3lzlz5qR63LNnz5qby7Fjx8zHc+fOmVswuY4X7OOmqWhRiXvhBYkfMEA8S4utAQPk/F13XajLsZmItLND0dbhQTuHB+0c220dyLEiHm42b95swsyZM2dMr83s2bOlcuXKfvfdt2+fFC1a1Gub3tftqRkxYoQMGTIkxfaFCxdK7ty5JRQWLVok4VT43Dlp6LMtLilJ1kybJn9WqyZ2Fe52djLaOjxo5/CgnWOzrU+dOhU74aZChQqyadMmOXr0qMyaNUs6duwoy5YtSzXgBGrgwIFevT3ac1O6dGlp1qyZKWIOJk2V+oNs2rSpJCYmSthUry7Wc89JnK5x8w9LRK5LSBCrZUuxm4i1swPR1uFBO4cH7Rzbbe0aeYmJcJM9e3YpV66c+bxWrVqybt06U1vz9ttvp9i3WLFisn//fq9tel+3pyZHjhzm5ksbO1Qv7lAe26+yZUVGjrxwZfB/6BBVgq5i3L69LYemItLODkZbhwftHB60c2y2dSDHibp1bpKTk71qZDzp8NXixYu9tmkyTK1Gx1Fq1065jfVuAAAOFNGeGx0yatGihVx++eVy/PhxmT59uixdulQ+//xz83iHDh2kZMmSpm5G9ezZUxo1aiSvvPKKtGrVSt5//30zhXzChAmRfBrRNWvKY2jKPWvqppsidVYAAIRdRHtuDhw4YAKM1t00btzYDElpsNExOrVz507Zu3eve/8GDRqYAKRhpkaNGqZGR2dKVa1aNYLPIkro0JMOTfkaMIBLMQAAHCWiPTeTJ09O83HtxfHVtm1bc0OAQ1M2rbsBACDqa26QBSzoBwAA4cZWGJoCAIBwYzvMmgIAOBzhxm4YmgIAOBzhxm4YmgIAOBzhxo4YmgIAOBjhxilDU3r/n8tcAABgZ4Qbuw5N+a7abFki/6z8DACAnRFu7Kp5c5E4vXymR7jp2pW6GwCA7RFu7Oqnny4EGk/U3QAAHIBwY1dMCQcAOBThxq6YEg4AcCjCjZ0xJRwA4ECEGztjSjgAwIEIN3bGlHAAgAMRbuyOKeEAAIch3NgdU8IBAA5DuLE76m4AAA5DuLE76m4AAA5DuHFK3Y0n6m4AADZGuHFK3Y0v6m4AADZFuHFq3U18PHU3AABbItw4pe7mgQe8t7Vvf2E7AAA2Q7hxAq2tmTbNe9vUqdTcAABsiXDjlJqb5GTvbdTcAABsinDjBKx1AwBwEMKNk9a68b0MA2vdAABsiHDjFFxjCgDgEIQbp6DuBgDgEIQbp2CtGwCAQxBunFZ34xlwRoxgrRsAgO0Qbpykc2eRoUMv3h8wQGTy5EieEQAAQUe4cRItHn722Yv3tQaHomIAgM0QbpyEomIAgAMQbpyExfwAAA5AuHESFvMDADgA4cZpWMwPAGBzhBunoe4GAGBzhBunoe4GAGBzhBunoe4GAGBzhBsnou4GAGBjhBsnou4GAGBjhBsnou4GAGBjhBsn1914ou4GAGAThBunou4GAGBThBsn191ooPFE3Q0AwAYIN05F3Q0AwKYIN05F3Q0AwKYIN05G3Q0AwIYiGm5GjBghderUkXz58kmRIkWkTZs2sn379jS/ZsqUKRIXF+d1y5kzZ9jO2VaouwEA2FBEw82yZcuke/fusnr1alm0aJGcO3dOmjVrJidPnkzz6/Lnzy979+51337//fewnbOtUHcDALChhEh+888++yxFr4z24GzYsEFuvPHGVL9Oe2uKFSsWhjN0SN3Nww+nrLvp3DmSZwYAgD1qbo4ePWo+XnrppWnud+LECbniiiukdOnScscdd8jWrVvDdIY2RN0NAMBmItpz4yk5OVl69eolDRs2lKpVq6a6X4UKFeSdd96R6tWrmzA0atQoadCggQk4pbQnwsfZs2fNzeXYsWPmow6B6S2YXMcL9nFDKe6HHyTBT93N+W3bxCpaVKJRLLZzrKKtw4N2Dg/aObbbOpBjxVmW7ztbZHTr1k0WLFggK1as8BtS0nqylSpVkvvvv1+GDRuW4vHBgwfLkCFDUmyfPn265M6dW5wu56FD0qxLF30huLclx8XJookT5UzhwhE9NwAAXE6dOiXt2rUzHRtaexv14ebxxx+XTz75RJYvXy5ly5YN+Ovbtm0rCQkJMmPGjAz13Ohw1qFDh9JtnEBp0NLC6KZNm0piYqLEirh335X4rl3FNThlxcVJ0vjxYj30kESjWG3nWERbhwftHB60c2y3tb5/Fy5cOEPhJqLDUpqrevToIbNnz5alS5dmKtgkJSXJ5s2bpWXLln4fz5Ejh7n50sYO1Ys7lMcOCW07rbv5J+dqL07CY49d2B5AL1q4xVw7xzDaOjxo5/CgnWOzrQM5TkQLinUa+NSpU80Qka51s2/fPnM7ffq0e58OHTrIwIED3feHDh0qCxculF9//VU2btwo7du3N1PBH/ac8YPAsN4NAMBGItpzM27cOPPxpptu8tr+7rvvyoMPPmg+37lzp2TzWIvl8OHD0qVLFxOCChYsKLVq1ZKVK1dK5cqVw3z2NlzvJjn54jbWuwEAxKiID0ulR4erPI0ZM8bcEESsdwMAsJGoWucGEV7vxhPr3QAAYhThBhfrbnxRdwMAiEGEG1zAdaYAADZBuMHFupu33/be5qq7AQAghhBucNGtt3rfp+4GABCDCDe4iLobAIANEG6Qdt1NfDx1NwCAmEK4gXfdzQMPeG9r3z6qL8EAAIAvwg0u0tqaadO8t02dSs0NACCmEG7gXXPjeQkGRc0NACDGEG5wEWvdAABsgHCDlNeYiou7uI21bgAAMYZwg5TXmPINN6x1AwCIIYQbeKPuBgAQ4wg3SL/uRq1fH4mzAQAgYIQbpKy7GTky5fYBAxiaAgDEBMINUqpdO+U2hqYAADGCcIOUmBIOAIhhhBukxJRwAEAMI9zAP6aEAwBiFOEG/jElHAAQowg38I8p4QCAGEW4gX9MCQcAxCjCDVLHlHAAQAwi3CB1DE0BAGIQ4QapY2gKABCDCDdIG0NTAIAYQ7hB2hiaAgDEGMIN0sbQFAAgxhBukD6GpgAATgo3SUlJsmnTJjl8+HBwzgjRhwtpAgDsHG569eolkydPdgebRo0aSc2aNaV06dKydOnSUJwjouVCmp64kCYAwC7hZtasWVKjRg3z+f/+9z/ZsWOHbNu2TZ588kkZNGhQKM4R0YALaQIA7BpuDh06JMWKFTOfz58/X9q2bStXX321dOrUSTZv3hyKc0S0XEhTA40n6m4AAHYIN0WLFpXvv//eDEl99tln0rRpU7P91KlTEh8fH4pzRDRgSjgAwK7h5qGHHpJ77rlHqlatKnFxcdKkSROzfc2aNVKxYsVQnCOiAVPCAQAxIiHQLxg8eLAJNrt27TJDUjly5DDbtddmgL7RwZlTwjX8AAAQi+FG3X333V73jxw5Ih07dgzWOSHah6aSk1MOTd10U6TOCgCArA1Lvfjii/LBBx+47+sQVaFChaRUqVLy3XffBXo4xBKGpgAAdgw348ePN2vaqEWLFpnbggUL5NZbb5W+ffuG4hwRTVitGABgt2Gpffv2ucPNvHnzTM9Ns2bNpEyZMlKvXr1QnCOibWhK17vxnBau91mtGAAQqz03BQsWNMXESqeCu2ZLWZZlpocDAADEVLj517/+Je3atTPr2/z555/SokULs/2bb76Rcvz17szF/PT+2LGROiMAALIWbsaMGSOPP/64VK5c2dTb5M2b12zfu3evPPbYY4EeDrE6LOVrzBiKigEAsVlzk5iY6LdwWK8tBYfMmOrTR2TUKO/trHcDAIjVnhv1yy+/SI8ePUy9jd6eeOIJ+fXXX4N/dohOPXtyKQYAgH3Czeeff26GpNauXSvVq1c3N730gmuYCg7AejcAADsNS+klFnQIaqTPm5tuf+qpp9wX0oTNcSkGAIBdem5++OEH6dy5c4rtnTp1MlcLh0NwlXAAgF3CzWWXXSabNm1KsV23FSlSJFjnhWjH0BQAwC7hpkuXLvLII4+Ya0x99dVX5qZDVF27djWPBWLEiBFSp04dyZcvnwlGbdq0ke3bt6f7dR9++KFUrFhRcubMKdWqVZP58+cH+jQQDFyKAQBgh3DzzDPPyLPPPiuvv/66NGrUyNzeeOMNGTx4sHksEMuWLZPu3bvL6tWrTTHyuXPnzKUcTp48merXrFy5Uu6//34zNKYLB2og0tuWLVsCfSrIKoamAAB2CDdxcXGmoHj37t1y9OhRc9PPtddGg0cg9PINDz74oFSpUkVq1KghU6ZMkZ07d8qGDRtS/ZqxY8eai3T269dPKlWqJMOGDZOaNWuagIUoGZp66imGpgAAsTNbypMOJ7n89NNPcsMNN2Tp+lIalNSll16a6j6rVq2S3r17e21r3ry5zJkzx+/+Z8+eNTeXY8eOmY/aS6S3YHIdL9jHjWZx11yT8kWUnCxJY8ZIsr/gEwRObOdIoa3Dg3YOD9o5tts6kGNlKdwEU3JysvTq1UsaNmwoVatWTfOq5EWLFvXapvd1e2p1PUOGDEmxfeHChZI7d24JBSet95Pz0CFppiHHZ3u2V1+VLypXljOFC4fsezupnSONtg4P2jk8aOfYbOtTp07FXrjR2hutm1mxYkVQjztw4ECvnh7tuSldurSp7cmfP39Qv5emSv1B6lo/epkKp0j+/nuJHz3aa1tccrI0vuIKsRo1Cvr3c2o7RwJtHR60c3jQzrHd1q6Rl5gJN3ohznnz5sny5culVDoLwBUrVkz279/vtU3v63Z/cuTIYW6+tLFD9eIO5bGjkl5X7NVXzXCUpwRdMqBJk5B9W8e1cwTR1uFBO4cH7RybbR3IcTIcbubOnZvm4zt27JBAWZZlrlE1e/ZsWbp0qZQtWzbdr6lfv74sXrzYDGG5aDrU7YhwYXH//ikLi++7jxWLAQBhleFwo9OtMzKTKtChqOnTp8snn3xiipNddTMFChSQXLlymc87dOggJUuWNLUzqmfPnmb6+SuvvCKtWrWS999/X9avXy8TJkwI6HsjDGveaE/O2LEiL78ciTMCADhUtkAKftO7BTpTaty4cWaG1E033STFixd33z744AP3Pjo1fO/eve77DRo0MIFIw4xOH581a5aZKZVWETLCtOaNv3A7ZgzTwgEAYRXRmhsdlkqPDlf5atu2rbkhiujQU58+IqNGeW/nYpoAgGhfxA9IVc+erFgMAIg4wg2ChxWLAQBRgHCD8BUWAwAQBoQbBBeFxQCAWAw3R44ckUmTJpnVf//66y+zbePGjfLHH38E+/wQq4XFvlyFxQAARFu4+e677+Tqq6+WF198UUaNGmWCjvr4449N2AHknnv8b8+TJ9xnAgBwoIDDjV6n6cEHHzRXAc+ZM6d7e8uWLc3lEwA5ccL/9pkzw30mAAAHCjjcrFu3Trp27Zpiu64inNqVueEw1N0AAGIp3OhFKP1dmfPHH3+Uyy67LFjnhVhG3Q0AIJbCze233y5Dhw41lzN3XU9KL5Hw1FNPyV133RWKc0QsYkE/AECshBu9YOWJEyekSJEicvr0aXMRy3LlypkLXw4fPjw0Z4nYw4J+AIBYubaUXrF70aJFsmLFCjNzSoNOzZo1pUmTJqE5Q8QurhQOAIilC2def/315gakW1jse4HU0aMvDFtxMU0AQDSEm9dee83vdq290anhOkR14403Snx8fDDOD3a8Uji9NwCAaAo3Y8aMkYMHD8qpU6ekYMGCZtvhw4cld+7ckjdvXjlw4IBceeWVsmTJEildunQozhmxRHtoXnmF3hsAQPQWFL/wwgtSp04ds4jfn3/+aW46DbxevXoyduxYM3OqWLFi8uSTT4bmjGGPaeFcTBMAEC3h5umnnza9N1dddZV7mw5F6aUY9PILpUqVkpdeekm+/vrrYJ8rYpX20Phb1E97b5g5BQCIdLjZu3evnD9/PsV23eZaobhEiRJy/Pjx4JwhYh+9NwCAaA43N998s7n8wjfffOPepp9369ZNbrnlFnN/8+bNUrZs2eCeKWIbvTcAgGgNN5MnT5ZLL71UatWqZS7FoLfatWubbfqY0sJiXewPcKP3BgAQrbOltFhYF/Hbtm2bKSRWFSpUMDfP3h0gBWZOAQCisefGpWLFiuY6U3rzDDZAqui9AQBE6wrFu3fvlrlz55pp33///bfXY6P1r3AgNfTeAACiLdwsXrzY9NboQn06NFW1alX57bffxLIsc40pINOrFj//vMj48ZE6MwCAU4eldC2bvn37mhlRermFjz76SHbt2mWuDt62bdvQnCWcMXPq7bdThh4AAEIdbn744Qfp0KGD+TwhIUFOnz5tZkcNHTpUXnzxxUAPBydKrfZGPfUUU8MBAOENN3ny5HHX2RQvXlx++eUX92OHDh3K2tnAOVLrvdHhqZ9/jsQZAQCcGm6uu+46WbFihfm8ZcuW0qdPHxk+fLh06tTJPAZkuPdm4ED/j+XJE+6zAQDYSMDhRmdD6UUy1ZAhQ6Rx48bywQcfSJkyZdyL+AEZ0qSJ/+0zZ4b7TAAATp0tlZSUZKaBV69e3T1ENZ7ZLcis8uUvDE0xLRwAEKmem/j4eGnWrJkcPnw4mOcAp0prUT+dFg4AQDiGpXRdm19//TUz3wtIiWnhAIBIh5vnn3/erHMzb9482bt3rxw7dszrBgRtWnj//kwLBwCEPtzoDKlvv/3WrFJcqlQpKViwoLldcskl5iMQtN4brcXhmlMAgFBffmHJkiWBfgmQfu+NLgCpPTW+KC4GAIQ63OhlFoCg69dPRBeE1FobT1xzCgAQ6mEp9dVXX0n79u2lQYMG8scff5ht7733nntxPyBTnn6a4mIAQPjDjV4os3nz5pIrVy7ZuHGjnD171mw/evSovPDCC1k/IzgXxcUAgEjNltKF+yZOnCiJiYnu7Q0bNjRhBwhZcTFr3wAAQhFutm/fLjfeeGOK7QUKFJAjR44EejjAf3GxPwxPAQBCEW6KFSsmP/u5arPW21x55ZWBHg7wX1zctav/xxieAgAEO9x06dJFevbsKWvWrJG4uDjZs2ePTJs2zSzs161bt0APBwRWXGxZku2NNyJxRgAAu04FHzBggCQnJ5urgZ86dcoMUeXIkcOEmx49eoTmLOE8aax9k23MGMlZuXJETgsAYMNwo701gwYNkn79+pnhqRMnTkjlypUlb968oTlDOHt46ttvRaZN89ocZ1lScNu2iJ0WAMBmw1JTp041PTbZs2c3oaZu3boEG4TO7bf73Vx03bqwnwoAwKbh5sknn5QiRYpIu3btZP78+ZKUlBSaMwNUgwZ+N1++bJnEvfJK2E8HAGDDcKNXAn///ffN8NQ999wjxYsXl+7du8vKlStDc4ZwNq296ds3xWYtNY7/z3+YOQUAyHq4SUhIkNtuu83MkDpw4ICMGTNGfvvtN7n55pvlqquuCvRwQKYX9tPaGxb2AwAE5dpSLrlz5zaXYmjRooWUL1/ehBwg7Av76bRxAACyEm60oFh7blq2bCklS5aUV199Ve68807ZunVrQMdZvny5tG7dWkqUKGGGuebMmZPm/kuXLjX7+d727duXmacBuyzsN3w4KxcDADIfbu677z5TUKyFxboisQYOnRI+bNgwqVixYkDHOnnypNSoUUPefPPNgC8BobU/rpueDxy8sJ9i5WIAQGbXuYmPj5eZM2ea4Sj93NOWLVukatWqGT6WDmfpLVAaZi655JKAvw72GJ6y+vc3BcVeXPU348dH5twAALHbc+MajnIFm+PHj8uECRPMejfaCxMO11xzjZml1bRpU/n666/D8j0RJfr1k6QBA8Ty9xj1NwCAzPTceNbLTJ48WT766CNTM/Ovf/0r4OGlQGmgGT9+vNSuXVvOnj0rkyZNkptuuslc56pmzZp+v0b305vLsWPHzMdz586ZWzC5jhfs48LbuWeekf0bN0rZhQtTPGYNHy5JefOK1adPRM7NbnhNhwftHB60c2y3dSDHirMs7c/PGC3cnTJligk1GhJ0nRsNG99++61ZrTgrtDB49uzZ0qZNm4C+rlGjRnL55ZfLe++95/fxwYMHy5AhQ1Jsnz59upnthdiU89AhafbwwymHpzTgiMjCSZPkTOHCETgzAEAo6GQmXUD46NGjkj9//uD03OisJu2tadWqlZkddeutt5qhKQ03kaTDYStWrEj18YEDB0rv3r3d9zWUlS5dWpo1a5Zu42QmVS5atMgMlyUmJgb12EjZzn8PHy7ZBw1KEXD0fpM1ayQ5xD2JTsBrOjxo5/CgnWO7rV0jLxmR4XCzYMECeeKJJ6Rbt25mTZtosWnTJjNclRq9YrnefGljh+rFHcpj46Js/fpJ3KlTF6aC+4ifOFHir77a7+rGCByv6fCgncODdo7Ntg7kOBkuKNbeES0erlWrltSrV0/eeOMNOXTokGSFXlFcw4ne1I4dO8znO3fudPe6dOjQwb2/9hh98sknZuq5zszq1auXfPnll+byD3AonSGV2vo3ujYO08MBwHEyHG6uu+46mThxollXpmvXrub6UlpInJycbLqeNPgEav369XLttdeam9LhI/382WefNff1e7mCjvr777+lT58+Uq1aNVNro7U+X3zxhTRu3Djg7w0bSWuGlJ9eHQCAvQU8FTxPnjzSqVMn05OzefNmEzZGjhxp1p65/fbbAzqWznTSembfmxYtK/2oiwS69O/f3/TanD59Wv78809ZsmSJuaYVHE7Xv3nkEf+P6fRwem8AwFGydG2pChUqyEsvvSS7d++WGTNmBO+sgEA984z/7VxcEwAcJ0vhxkVnTekU7rlz5wbjcEDmem9eesn/YyzuBwCOEpRwA8TExTUJOADgCIQbOOfimgQcAHAEwg1seXHNVBFwAMD2CDew5/DUoEGpP07AAQBbI9zAnnSGFAEHAByJcANnB5xRo8J5RgCAMCDcwNkBp39/FvkDAJsh3MDZAUcX+Vu1KtxnBAAIIcINnBNwHnjA/2MsPgkAtkK4gXOMHOl/+9SpFBcDgI0QbuCsNXD69vX/GLOnAMA2CDdwlp49WcEYAGyOcANnYQVjALA9wg2chxWMAcDWCDdwJlYwBgDbItzAuTIScJ54IpxnBAAIAsINnC29gPP66yK33RbOMwIAZBHhBkgv4Hz6KT04ABBDCDdARntwqMEBgJhAuAE8A06PHqk/TpExAMQEwg3g6bXXRFq1Sv1xAg4ARD3CDeBr3jx6cAAghhFugNR6cFgHBwBiEuEGSA0L/QFATCLcAFkNOO3bi+zeHc6zAgCkgXADZDXgTJsmUrq0yOTJ4TwrAEAqCDdAMAKOevhhenAAIAoQboBgBpyBA8N1NgCAVBBugGAGnKlTKTIGgAgj3ACBosgYAKIa4QYIZZHxyy+H86wAAIQbIMQ1OP37M0wFAGFGuAFCHXBY7A8AwopwA4Qr4DzxRLjOCAAcjXADBCvgpFdf8/rrIrfdFq4zAgDHItwAwdK3r8iuXRdmSqXm00/pwQGAECPcAMFUqpTIe++lPUylPThMFQeAkCHcAKEapurRI/XHmSoOACFDuAFC5bXXRFq1SnsfpooDQNARboBQmjcv7R4cxYrGABBUhBsgHD046U0VZ5gKAIKGcANEy1Rx1zDVqFHhOCMAsC3CDRBNU8VVv34i69aF66wAwHYIN0C0TRVXdesyRAUAmUS4AaJ1mIqZVACQKYQbIJLDVGvXpr0PM6kAIGCEGyCS6tQReemltPdhJhUABIRwA0SaFhBndCYVvTgAEN3hZvny5dK6dWspUaKExMXFyZw5c9L9mqVLl0rNmjUlR44cUq5cOZkyZUpYzhWIiplU9OIAQHSHm5MnT0qNGjXkzTffzND+O3bskFatWsnNN98smzZtkl69esnDDz8sn3/+ecjPFYiamVSK9XAAIFUJEkEtWrQwt4waP368lC1bVl555RVzv1KlSrJixQoZM2aMNG/ePIRnCoR5JtUll1wYrkqLPt6o0YW6HQBAdISbQK1atUqaNGnitU1DjfbgpObs2bPm5nLs2DHz8dy5c+YWTK7jBfu4cGA79+wpctddkm3QIMk2Y4bEpbKbVbeuJI0cKVbv3iE5DUe0dRSgncODdo7ttg7kWDEVbvbt2ydFixb12qb3NbCcPn1acuXKleJrRowYIUOGDEmxfeHChZI7d+6QnOeiRYtCclw4sJ3vvVeuyp5dqvz3v34Djm6LHzBAds2fLz906CBnChcOyWk4oq2jAO0cHrRzbLb1qVOn7BluMmPgwIHS2+OvWg1CpUuXlmbNmkn+/PmD+r00VeoPsmnTppKYmBjUY8PB7dyypZx/5BFJaNgw1YBz+fLlUnr58qD34jiurSOEdg4P2jm229o18mK7cFOsWDHZv3+/1za9ryHFX6+N0llVevOljR2qF3cojw2HtnODBhfWw9FC4lRoyEkYMEBk82aRkSMvFCgHiaPaOoJo5/CgnWOzrQM5Tkytc1O/fn1ZvHix1zZNhrodsL2MrofDdHEADhfRcHPixAkzpVtvrqne+vnOnTvdQ0odOnRw7//oo4/Kr7/+Kv3795dt27bJW2+9JTNnzpQnn3wyYs8BiMr1cBTXpgLgUBENN+vXr5drr73W3JTWxujnzz77rLm/d+9ed9BROg38008/Nb01uj6OTgmfNGkS08DhzPVwMtIzo9emIuAAcJiI1tzcdNNNYllWqo/7W31Yv+abb74J8ZkBMdKLc9992sUpMnVq2gHnt9+CXocDANEqpmpuAGSyF4c6HAAOQrgB7NKLs3Zt+vtx8U0ADkC4AexCL8MwaVL6+9GLA8DmCDeAnXTuHNhsKnpxANgQ4QZw8mwqenEA2BDhBrAr1sQB4FCEG8DOAl0Th2EqADZAuAGcIKO9OAxTAbABwg3gtF6cQYPS35diYwAxjHADOM3zz2e42Djhyiul+ltvEXIAxBTCDeBEGRymitNrui1caEKOTJ4cttMDgKwg3ABOFUCxsYYcefhhkXXrwnFmAJAlhBvA6QKZMl63rkjXrgxTAYhqhBsAgU0ZnzDhwowqQg6AKEW4AZC5XhxXyGHaOIAoQ7gBkOqUcSsj+zNtHECUIdwA8O/55yVpxIiMBRwW/wMQRQg3AFJl9ekjCydNkqQuXTL2BfTiAIgChBsAaTpTuLAkv/nmhVqcRx/NeC8OBccAIoRwAyDjtTjjxgVecEzIARBmhBsAobtGlSLkAAgzwg2A0F6jyjfkZDQUAUAmEW4AZH1dnIzU4ri88ILIddfRiwMgZAg3AIJXi5PRkLNmDUNVAEKGcAMgciGHehwAIUC4ARBchBwAEUa4ARD6kKM1NoGEnAceIOQAyDTCDYDQh5xVqwKbJTV9Oj05ADKNcAMgfFPHA51ZxXAVgEwg3ACI7noc3+GqmTMJOgDSRLgBEDshR4er7r2X3hwAaSLcAIiOkNOoUWBfy5AVgFQQbgBER8hZulRk7VqR1q0D+1qGrAD4INwAiB516ojMnRv4cJXvkBVBB3A0wg2A6K/JiYvLWtAh5ACOQrgBEP0hZ+fOCz0xd94Z+DFca+bQmwM4BuEGQGyEnLZtRT7+WOTllwPvyVEMWwGOQbgBEFv69r3Yk9O+fdaDjhYwr1sXijMFECGEGwCx25Pz3ntZDzrz5onUrXvh+lc6BEaPDhDzEiJ9AgAQlKCjtxEjLlzHavRokdWrAzvOmjUXbi7t2olcf71IoUIiDRpc+D4AYgI9NwDsF3Q04LjWzMlMb45r6Oqxxxi+AmIQPTcA7L1mjg4xadjRz6dNE7GszB1Ph6/0Vq+eSMeOF7bRqwNEJcINAOcNW2nQmTo1c8fzHb5SDGEBUYVhKQDOLETWBQK1CDkYfIewdKo5xclAxNBzA8C5QUdDjqs3588/Rb7+OmtDV55hR2++PTuK3h0g5Ag3AJzN1Zuj9FIPvmEns8NXaYUd36EsrQ8CEDSEGwBIL+wMHBickJNK4NFfxNfeeKPE6Zo9Cf/8WqaHB8g0wg0ABDp8pYI1hCUiOln98uXLRfTmiyEtIGCEGwAItEfHdwgrq9PMMzOkVaWKyIEDIkWKiJQrR+gBoi3cvPnmm/Lyyy/Lvn37pEaNGvL6669LXV0O3Y8pU6bIQw895LUtR44ccubMmTCdLQCkMc08BD07KfiGHX+9PJ7o8YHDRDzcfPDBB9K7d28ZP3681KtXT1599VVp3ry5bN++XYroXyR+5M+f3zzuEpfZFUgBIBw9O8GciRVoL0964YfgAxuKeLgZPXq0dOnSxd0boyHn008/lXfeeUcGDBjg92s0zBQrVizMZwoAQZyJpcIReDIafho3FrnlFpGCBVM+RgBCjIlouPn7779lw4YNMlBnIvwjW7Zs0qRJE1mlvwBSceLECbniiiskOTlZatasKS+88IJU0fFnAIjB3p3zX30lm5ctk2pVq0qCrn4czsDjsnjxhVta0gpAihCEKBHRcHPo0CFJSkqSokWLem3X+9u2bfP7NRUqVDC9OtWrV5ejR4/KqFGjpEGDBrJ161Yp5ec/1NmzZ83N5dixY+bjuXPnzC2YXMcL9nHhjXYOH9o6DIoWlXN33CE7c+eWCk2bitW1q8jQoRKnVzV39fBoj/WqVZJtxgyJC3foCTAA6dkl33KLWI0apR6CDh+WuLNnJblVq7Cu8cPrWWK6rQM5VpxlRe5/yp49e6RkyZKycuVKqV+/vnt7//79ZdmyZbLG9/otqTzZSpUqyf333y/Dhg1L8fjgwYNlyJAhKbZPnz5dcufOHYRnAQDhkfPQISm4bZskHj8uiSdOSI6jRyX3wYNSYs0aM5081uibz1/ly8su7Q3y4Xp+Z/Pnl3P58nk9pvf/qlhRzhQuHMazRaSdOnVK2rVrZzo2tPY2antuChcuLPHx8bJ//36v7Xo/ozU1iYmJcu2118rPP//s93Ed8tKCZc+em9KlS0uzZs3SbZxAadBatGiRNG3a1JwXQoN2Dh/aOjba+fzu3Sl6ety9PdOnR23w0fMq9NNP5hYo00N0//1iVawocQcPinXZZWn3FB08KOcLF5Yf9u41fxDHZ8tmhtEs/cOaYbSY+N3hGnnJiIiGm+zZs0utWrVk8eLF0qZNG7NN62j0/uOPP56hY+iw1ubNm6Vly5Z+H9dp4nrzpY0dql/WoTw2LqKdw4e2jvJ2Llv2ws2X/h598UXvImZPwbq8RISCUfyMGQF9TbyIXJPWLLLDhy+uHZRGUMrwPhUqiLRu7ejwlBjE3x2BHCfis6W0V6Vjx45Su3Zts7aNTgU/efKke/ZUhw4dzNDVCJ1lIDoUPVSuu+46KVeunBw5csSsj/P777/Lww8/HOFnAgAxUMTsyTWDa948kR9/FPHX+xHDAShoU+izQq8Wn9r6Q8EOU2nt49pP14TTwGXz65lFPNzce++9cvDgQXn22WfNIn7XXHONfPbZZ+4i4507d5oZVC6HDx82U8d134IFC5qeH63ZqVy5cgSfBQDEcPjRkJOajAQgp4SgaAxPmTFsmEi9eiIdO2YtKKWxX1yBApLz9GmJlIgWFEeCjtkVKFAgQwVJmRljnD9/vhkiows/dGjn8KGtw8M27bx7d/ohSC1aJPLxx+E+O4SZFRcnSePHS8Ijj4T9/TviPTcAAIf0ArnoPhqEUqsFcvUMHDyYMiSFe+FDZJouWxCvw3JaExvmuiPCDQAgumqB0uK70nNqIcjTP/ucL1hQNv/xR2QXS3SYuKQkEZ3NTLgBACD4wcg6d052zp8vVbUnQWeS+V4OI4CglO4+S5aIfPGF48OTFR8vcXrV+jAj3AAAnCmzvUcZoZcVyuzQWyj2iUCtk6m5eestSYjAVHjCDQAAsRaeMuPRLNQ6Bbjf+QIFZPGpU3JLhw4SCYQbAACcIkyBS4cAz8yfL5FycQEZAAAAGyDcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAW3HctaWsfy4/f+zYsaAf+9y5c3Lq1Clz7MTExKAfHxfQzuFDW4cH7RwetHNst7Xrfdv1Pp4Wx4Wb48ePm4+lS5eO9KkAAIBMvI8XKFAgzX3irIxEIBtJTk6WPXv2SL58+SQuLi6ox9ZUqaFp165dkj9//qAeGxfRzuFDW4cH7RwetHNst7XGFQ02JUqUkGzZ0q6qcVzPjTZIKb3kewjpD5L/OKFHO4cPbR0etHN40M6x29bp9di4UFAMAABshXADAABshXATRDly5JDnnnvOfETo0M7hQ1uHB+0cHrSzc9racQXFAADA3ui5AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4CZI333xTypQpIzlz5pR69erJ2rVrI31KMWf58uXSunVrs/qkrh49Z84cr8e19v3ZZ5+V4sWLS65cuaRJkyby008/ee3z119/yQMPPGAWjbrkkkukc+fOcuLEiTA/k+g1YsQIqVOnjlmhu0iRItKmTRvZvn271z5nzpyR7t27S6FChSRv3rxy1113yf79+7322blzp7Rq1Upy585tjtOvXz85f/58mJ9NdBs3bpxUr17dvYhZ/fr1ZcGCBe7HaefQGDlypPn90atXL/c22jo4Bg8ebNrW81axYsXobGedLYWsef/9963s2bNb77zzjrV161arS5cu1iWXXGLt378/0qcWU+bPn28NGjTI+vjjj3UGnzV79myvx0eOHGkVKFDAmjNnjvXtt99at99+u1W2bFnr9OnT7n1uvfVWq0aNGtbq1autr776yipXrpx1//33R+DZRKfmzZtb7777rrVlyxZr06ZNVsuWLa3LL7/cOnHihHufRx991CpdurS1ePFia/369dZ1111nNWjQwP34+fPnrapVq1pNmjSxvvnmG/NzK1y4sDVw4MAIPavoNHfuXOvTTz+1fvzxR2v79u3Wf/7zHysxMdG0vaKdg2/t2rVWmTJlrOrVq1s9e/Z0b6etg+O5556zqlSpYu3du9d9O3jwYFS2M+EmCOrWrWt1797dfT8pKckqUaKENWLEiIieVyzzDTfJyclWsWLFrJdfftm97ciRI1aOHDmsGTNmmPvff/+9+bp169a591mwYIEVFxdn/fHHH2F+BrHhwIEDps2WLVvmblN9A/7www/d+/zwww9mn1WrVpn7+gspW7Zs1r59+9z7jBs3zsqfP7919uzZCDyL2FGwYEFr0qRJtHMIHD9+3Cpfvry1aNEiq1GjRu5wQ1sHN9zoH4/+RFs7MyyVRX///bds2LDBDJF4Xr9K769atSqi52YnO3bskH379nm1s15jRIcAXe2sH3Uoqnbt2u59dH/9eaxZsyYi5x3tjh49aj5eeuml5qO+ls+dO+fVztrtfPnll3u1c7Vq1aRo0aLufZo3b24ulLd169awP4dYkJSUJO+//76cPHnSDE/RzsGnwyE63OHZpoq2Di4tBdDSgSuvvNKUAOgwUzS2s+MunBlshw4dMr+4PH9YSu9v27YtYudlNxpslL92dj2mH3UM11NCQoJ543btg4uSk5NNXULDhg2latWqZpu2U/bs2U1ITKud/f0cXI/hos2bN5swo7UIWoMwe/ZsqVy5smzatIl2DiINjhs3bpR169aleIzXdPDoH5NTpkyRChUqyN69e2XIkCFyww03yJYtW6KunQk3gIP/0tVfSitWrIj0qdiWvglokNEeslmzZknHjh1l2bJlkT4tW9m1a5f07NlTFi1aZCZ0IHRatGjh/lyL5TXsXHHFFTJz5kwzySOaMCyVRYULF5b4+PgUFeF6v1ixYhE7L7txtWVa7awfDxw44PW4VuHrDCp+Ft4ef/xxmTdvnixZskRKlSrl3q7tpEOtR44cSbOd/f0cXI/hIv1Ltly5clKrVi0zU61GjRoyduxY2jmIdDhE/9/XrFnT9NTqTQPka6+9Zj7XngHaOjS0l+bqq6+Wn3/+Oepe04SbIPzy0l9cixcv9uru1/vaHY3gKFu2rHnxe7azjtNqLY2rnfWj/sfSX3YuX375pfl56F8YuDCdXoONDo9o22i7etLXcmJiolc761RxHVf3bGcdbvEMkvpXs0531iEXpE5fi2fPnqWdg6hx48amnbSHzHXTujutB3F9TluHhi6z8csvv5jlOaLuNR3U8mQHTwXXWTtTpkwxM3YeeeQRMxXcsyIcGZvtoNMD9aYvzdGjR5vPf//9d/dUcG3XTz75xPruu++sO+64w+9U8GuvvdZas2aNtWLFCjN7gqngF3Xr1s1Mp1+6dKnXdM5Tp055TefU6eFffvmlmc5Zv359c/OdztmsWTMznfyzzz6zLrvsMqbN+hgwYICZhbZjxw7zetX7OnNv4cKF5nHaOXQ8Z0sp2jo4+vTpY3536Gv666+/NlO6dSq3zrqMtnYm3ATJ66+/bn6out6NTg3XdVYQmCVLlphQ43vr2LGjezr4M888YxUtWtSEycaNG5v1Qzz9+eefJszkzZvXTC986KGHTGjCBf7aV2+69o2LhsXHHnvMTFvOnTu3deedd5oA5Om3336zWrRoYeXKlcv8ctNfeufOnYvAM4penTp1sq644grzO0F/gevr1RVsFO0cvnBDWwfHvffeaxUvXty8pkuWLGnu//zzz1HZznH6T3D7ggAAACKHmhsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAjhQXFydz5syJ9GkACAHCDYCwe/DBB0248L3deuutkT41ADaQEOkTAOBMGmTeffddr205cuSI2PkAsA96bgBEhAYZvdK7561gwYLmMe3FGTdunLRo0UJy5colV155pcyaNcvr6/Xqwrfccot5vFChQvLII4+YqxR7euedd6RKlSrme+mVi/WK6J4OHTokd955p+TOnVvKly8vc+fOdT92+PBhc2Xpyy67zHwPfdw3jAGIToQbAFHpmWeekbvuuku+/fZbEzLuu+8++eGHH8xjJ0+elObNm5swtG7dOvnwww/liy++8AovGo66d+9uQo8GIQ0u5cqV8/oeQ4YMkXvuuUe+++47admypfk+f/31l/v7f//997JgwQLzffV4hQsXDnMrAMiUoF+KEwDSoVd6j4+Pt/LkyeN1Gz58uHlcfzU9+uijXl9Tr149q1u3bubzCRMmmCsPnzhxwv34p59+amXLls3at2+fuV+iRAlr0KBBqZ6Dfo+nn37afV+PpdsWLFhg7rdu3dpcVR5A7KHmBkBE3HzzzaY3xNOll17q/rx+/fpej+n9TZs2mc+1J6VGjRqSJ08e9+MNGzaU5ORk2b59uxnW2rNnjzRu3DjNc6hevbr7cz1W/vz55cCBA+Z+t27dTM/Rxo0bpVmzZtKmTRtp0KBBFp81gHAg3ACICA0TvsNEwaI1MhmRmJjodV9DkQYkpfU+v//+u8yfP18WLVpkgpIOc40aNSok5wwgeKi5ARCVVq9eneJ+pUqVzOf6UWtxtPbG5euvv5Zs2bJJhQoVJF++fFKmTBlZvHhxls5Bi4k7duwoU6dOlVdffVUmTJiQpeMBCA96bgBExNmzZ2Xfvn1e2xISEtxFu1okXLt2bbn++utl2rRpsnbtWpk8ebJ5TAt/n3vuORM8Bg8eLAcPHpQePXrIv//9bylatKjZR7c/+uijUqRIEdMLc/z4cROAdL+MePbZZ6VWrVpmtpWe67x589zhCkB0I9wAiIjPPvvMTM/2pL0u27Ztc89kev/99+Wxxx4z+82YMUMqV65sHtOp259//rn07NlT6tSpY+5rfczo0aPdx9Lgc+bMGRkzZoz07dvXhKa77747w+eXPXt2GThwoPz2229mmOuGG24w5wMg+sVpVXGkTwIAfGtfZs+ebYp4ASBQ1NwAAABbIdwAAABboeYGQNRhtBxAVtBzAwAAbIVwAwAAbIVwAwAAbIVwAwAAbIVwAwAAbIVwAwAAbIVwAwAAbIVwAwAAbIVwAwAAxE7+H3UHk1khUdFNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curve\n",
    "plt.plot(x_axis, y_axis, marker='o', color ='red', markersize = 3)\n",
    "plt.title(\"Loss Curve on Synthetic Data\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nupd-Gr9P6vc"
   },
   "source": [
    "# Part D: Training on the Full Data (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r02Y9yvhPXy8"
   },
   "source": [
    "To train on the full data, you are going to need to do some pre-processing of the data.\n",
    "\n",
    "First, there are no \"questions\". You need to generate questions for each type of relation. There a number of ways to do this. The simplest is to just assume that a question is the name of a person and a relation, e.g., \"Alexander Hamilton birth date\". Another way would be to create templates for each type of relation. For example the \"birth date\" relation would have the following template: \"When was [name] born?\", filling in the [name]. Because there are a lot of different types of relations, you may want to remove the more obscure relations so you need fewer templates and also have a smaller vocabulary. Templates work well if the questions are expected to be almost identical to the templates. You may want to generate multiple templates per relation. Continuing the previous example, a second template would be: \"What is the birthdate of [name]?\".\n",
    "\n",
    "If you are feeling more ambitious, you could use GPT-J, GPT-NeoX, GPT-3 or ChatGPT to generate templates. It works decently well and you can get some variety of templates.\n",
    "\n",
    "The question should contain information about the person and some words that are representative of the relation even if the exact relation words aren't used (the KVMemNet should figure out that \"birthdate\" and \"born\" are correlated).\n",
    "\n",
    "You only put a subset of all key-value pairs into the KVMemNet. You need a technique for sub-selecting from all the key-value pairs in `DB`. You might just need the ones that are directly associated with the person (Alexander Hamilton has 23). You may need to mix in a few key-value pairs from another person's entries in the database to help ensure against accidental overfitting.\n",
    "\n",
    "The final challenge you will have in the training loop is that there may still be too many unique values in `Y` to encode and create one big tensor. In that case, you can at least use the values that you sent to the KVMemNet, along with as many other randomly selected values as you can fit into the GPU's memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I3CTqeEfa1m"
   },
   "source": [
    "Create as many cells below as you need. Save the output of your training and testing functions, reporting loss during training and accuracy during testing. 5 points for a training loop that reduces loss. 5 points for a training function with a correct accuracy computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-970kRwZ26n"
   },
   "source": [
    "**Create a training dataset and a non-overlapping testing dataset**\n",
    "\n",
    "If CPU memory becomes a problem you might want to consider a `DataLoader` so that data can be stored on file and pulled up when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "id": "V6VEnB_VS7Px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people list  40786\n",
      "Training :  32628\n",
      "Testing:  8158\n",
      "Training data:  8000\n",
      "Test data:  2000\n",
      "Total unique values:  10000\n",
      "Question: abdur rab nishtar birth_date\n",
      "Target: yes 1899 06 13\n"
     ]
    }
   ],
   "source": [
    "# Create your training and test sets here\n",
    "\n",
    "\n",
    "# Get people from DB\n",
    "people_list = list(DB.keys())\n",
    "print(\"people list \",len(people_list))\n",
    "\n",
    "# Split into train and test sets\n",
    "random.shuffle(people_list)\n",
    "train_indices = int(0.8 * len(people_list))\n",
    "people_train = people_list[:train_indices]\n",
    "people_test = people_list[train_indices:]\n",
    "print(\"Training : \", len(people_train))\n",
    "print(\"Testing: \", len(people_test))\n",
    "\n",
    "# Pick some relations based on the DB\n",
    "sample_relations = [\n",
    "    'birth_date', 'birth_place', 'death_date', 'death_place', \n",
    "    'office', 'party', 'spouse', 'children', 'religion'\n",
    "]\n",
    "\n",
    "# Function to create the dataset\n",
    "def create_dataset(people_list, max_samples=None):\n",
    "    # Dataset (question, key, value)\n",
    "    dataset = []\n",
    "    \n",
    "    # Loop through person list\n",
    "    for person in people_list:\n",
    "        person_data = DB[person]\n",
    "        \n",
    "        # Loop through each relation we want to use to create questions\n",
    "        for relation, value in person_data.items():\n",
    "            if relation in sample_relations:\n",
    "                # Create simple questions based on suggestion in the notes\n",
    "                # Question: person + relation (like \"alexander hamilton birth_date\")\n",
    "                question = f\"{person} {relation}\"\n",
    "                \n",
    "                # Key use to match value so set up name + relations, aka same as questions\n",
    "                key = question\n",
    "                # key = person\n",
    "                \n",
    "                # Value:\n",
    "                dataset.append((question, key, value))\n",
    "                \n",
    "                # Set up max_samples to limit the amount of data we will train later\n",
    "                if max_samples and len(dataset) >= max_samples:\n",
    "                    break\n",
    "        \n",
    "        if max_samples and len(dataset) >= max_samples:\n",
    "            break\n",
    "    return dataset\n",
    "\n",
    "# Create train and set data process\n",
    "train_data = create_dataset(people_train, max_samples=8000)  \n",
    "print(\"Training data: \", len(train_data))\n",
    "test_data = create_dataset(people_test, max_samples=2000) \n",
    "print(\"Test data: \", len(test_data))\n",
    "\n",
    "# Collect all unique values for the Y matrix\n",
    "all_values = []\n",
    "for _, _, value in train_data + test_data:\n",
    "    all_values.append(value)\n",
    "\n",
    "print(\"Total unique values: \", len(all_values))\n",
    "\n",
    "\n",
    "print(f\"Question: {train_data[10][0]}\")\n",
    "print(f\"Target: {train_data[10][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI3b5x2zfl8g"
   },
   "source": [
    "**Create your `KVMemNet`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "id": "OEKJ1KJxTBUJ"
   },
   "outputs": [],
   "source": [
    "# Set up your KVMemNet here\n",
    "\n",
    "vocab_size = VOCAB.num_words()\n",
    "embed_dim = 128  \n",
    "\n",
    "# Create the model for full dataset\n",
    "model = KVMemNet(vocab_size, embed_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Loss criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ug_8X-2fwYD"
   },
   "source": [
    "**Write and run a training loop, showing a loss plot**\n",
    "\n",
    "You may find it handy to also test your network on the test data periodically as it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "id": "-K6rxBHFTEPO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Training epoch 0 and batches 500\n",
      "Batch 0/500, Loss: 3.4013, Acc: 0.00\n",
      "Batch 100/500, Loss: 3.3957, Acc: 0.00\n",
      "Batch 200/500, Loss: 3.3922, Acc: 0.19\n",
      "Batch 300/500, Loss: 3.2936, Acc: 0.00\n",
      "Batch 400/500, Loss: 3.0183, Acc: 0.06\n",
      "Epoch 0/15 - Loss: 3.28, Accuracy: 0.05\n",
      "Training epoch 1 and batches 500\n",
      "Batch 0/500, Loss: 2.7666, Acc: 0.12\n",
      "Batch 100/500, Loss: 3.4269, Acc: 0.00\n",
      "Batch 200/500, Loss: 2.8860, Acc: 0.19\n",
      "Batch 300/500, Loss: 3.0138, Acc: 0.00\n",
      "Batch 400/500, Loss: 2.7059, Acc: 0.12\n",
      "Epoch 1/15 - Loss: 2.84, Accuracy: 0.12\n",
      "Training epoch 2 and batches 500\n",
      "Batch 0/500, Loss: 2.2660, Acc: 0.38\n",
      "Batch 100/500, Loss: 2.6340, Acc: 0.19\n",
      "Batch 200/500, Loss: 2.1195, Acc: 0.44\n",
      "Batch 300/500, Loss: 2.8243, Acc: 0.25\n",
      "Batch 400/500, Loss: 1.7543, Acc: 0.62\n",
      "Epoch 2/15 - Loss: 2.22, Accuracy: 0.31\n",
      "Training epoch 3 and batches 500\n",
      "Batch 0/500, Loss: 1.6278, Acc: 0.56\n",
      "Batch 100/500, Loss: 2.0149, Acc: 0.38\n",
      "Batch 200/500, Loss: 1.5723, Acc: 0.50\n",
      "Batch 300/500, Loss: 1.6578, Acc: 0.56\n",
      "Batch 400/500, Loss: 0.8743, Acc: 0.81\n",
      "Epoch 3/15 - Loss: 1.40, Accuracy: 0.63\n",
      "Training epoch 4 and batches 500\n",
      "Batch 0/500, Loss: 1.1721, Acc: 0.69\n",
      "Batch 100/500, Loss: 1.1384, Acc: 0.75\n",
      "Batch 200/500, Loss: 0.9618, Acc: 0.75\n",
      "Batch 300/500, Loss: 1.3611, Acc: 0.75\n",
      "Batch 400/500, Loss: 0.5964, Acc: 0.88\n",
      "Epoch 4/15 - Loss: 0.95, Accuracy: 0.78\n",
      "Training epoch 5 and batches 500\n",
      "Batch 0/500, Loss: 0.5722, Acc: 0.88\n",
      "Batch 100/500, Loss: 1.1149, Acc: 0.69\n",
      "Batch 200/500, Loss: 0.5443, Acc: 0.88\n",
      "Batch 300/500, Loss: 0.9291, Acc: 0.69\n",
      "Batch 400/500, Loss: 0.4404, Acc: 0.88\n",
      "Epoch 5/15 - Loss: 0.66, Accuracy: 0.87\n",
      "Training epoch 6 and batches 500\n",
      "Batch 0/500, Loss: 0.4254, Acc: 0.94\n",
      "Batch 100/500, Loss: 0.8453, Acc: 0.75\n",
      "Batch 200/500, Loss: 0.5745, Acc: 0.81\n",
      "Batch 300/500, Loss: 0.7498, Acc: 0.81\n",
      "Batch 400/500, Loss: 0.3222, Acc: 1.00\n",
      "Epoch 6/15 - Loss: 0.48, Accuracy: 0.93\n",
      "Training epoch 7 and batches 500\n",
      "Batch 0/500, Loss: 0.5610, Acc: 0.94\n",
      "Batch 100/500, Loss: 0.6357, Acc: 0.94\n",
      "Batch 200/500, Loss: 0.4083, Acc: 1.00\n",
      "Batch 300/500, Loss: 0.8996, Acc: 0.75\n",
      "Batch 400/500, Loss: 0.2996, Acc: 0.94\n",
      "Epoch 7/15 - Loss: 0.41, Accuracy: 0.94\n",
      "Training epoch 8 and batches 500\n",
      "Batch 0/500, Loss: 0.2067, Acc: 1.00\n",
      "Batch 100/500, Loss: 0.4917, Acc: 0.94\n",
      "Batch 200/500, Loss: 0.6183, Acc: 0.94\n",
      "Batch 300/500, Loss: 0.5730, Acc: 0.94\n",
      "Batch 400/500, Loss: 0.1681, Acc: 1.00\n",
      "Epoch 8/15 - Loss: 0.35, Accuracy: 0.96\n",
      "Training epoch 9 and batches 500\n",
      "Batch 0/500, Loss: 0.2367, Acc: 0.94\n",
      "Batch 100/500, Loss: 0.4070, Acc: 1.00\n",
      "Batch 200/500, Loss: 0.1775, Acc: 1.00\n",
      "Batch 300/500, Loss: 0.4675, Acc: 1.00\n",
      "Batch 400/500, Loss: 0.1427, Acc: 1.00\n",
      "Epoch 9/15 - Loss: 0.30, Accuracy: 0.97\n",
      "Training epoch 10 and batches 500\n",
      "Batch 0/500, Loss: 0.1485, Acc: 1.00\n",
      "Batch 100/500, Loss: 0.3816, Acc: 0.94\n",
      "Batch 200/500, Loss: 0.2512, Acc: 1.00\n",
      "Batch 300/500, Loss: 0.3992, Acc: 0.94\n",
      "Batch 400/500, Loss: 0.1576, Acc: 1.00\n",
      "Epoch 10/15 - Loss: 0.28, Accuracy: 0.97\n",
      "Training epoch 11 and batches 500\n",
      "Batch 0/500, Loss: 0.0723, Acc: 1.00\n",
      "Batch 100/500, Loss: 0.4160, Acc: 0.94\n",
      "Batch 200/500, Loss: 0.2754, Acc: 0.94\n",
      "Batch 300/500, Loss: 0.4264, Acc: 0.94\n",
      "Batch 400/500, Loss: 0.0971, Acc: 1.00\n",
      "Epoch 11/15 - Loss: 0.27, Accuracy: 0.97\n",
      "Training epoch 12 and batches 500\n",
      "Batch 0/500, Loss: 0.1070, Acc: 1.00\n",
      "Batch 100/500, Loss: 0.2731, Acc: 1.00\n",
      "Batch 200/500, Loss: 0.2726, Acc: 0.94\n",
      "Batch 300/500, Loss: 0.4769, Acc: 0.94\n",
      "Batch 400/500, Loss: 0.1537, Acc: 1.00\n",
      "Epoch 12/15 - Loss: 0.24, Accuracy: 0.98\n",
      "Training epoch 13 and batches 500\n",
      "Batch 0/500, Loss: 0.1314, Acc: 1.00\n",
      "Batch 100/500, Loss: 0.3261, Acc: 1.00\n",
      "Batch 200/500, Loss: 0.1793, Acc: 1.00\n",
      "Batch 300/500, Loss: 0.3326, Acc: 1.00\n",
      "Batch 400/500, Loss: 0.1695, Acc: 1.00\n",
      "Epoch 13/15 - Loss: 0.23, Accuracy: 0.98\n",
      "Training epoch 14 and batches 500\n",
      "Batch 0/500, Loss: 0.0543, Acc: 1.00\n",
      "Batch 100/500, Loss: 0.3428, Acc: 0.94\n",
      "Batch 200/500, Loss: 0.1619, Acc: 1.00\n",
      "Batch 300/500, Loss: 0.4389, Acc: 0.88\n",
      "Batch 400/500, Loss: 0.1513, Acc: 1.00\n",
      "Epoch 14/15 - Loss: 0.22, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Training loop goes here\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Implement batch data processing first, return list of batches of data\n",
    "def split_data_to_batches(full_data, batch_size = 16):\n",
    "    batches = []\n",
    "    for i in range(0, len(full_data), batch_size):\n",
    "        batch = full_data[i:i + batch_size]\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "# Implement batch data processing step\n",
    "# Tokenize, convert to multihot\n",
    "# convert to tensor, set up target\n",
    "# From partB, we need question, key, value data plus the target for loss calculation\n",
    "def batch_data_processing(batch_data, vocab, max_key = 30):\n",
    "    # The main idea in batch data is that even though we have correct question,key,value.\n",
    "    # We want to introduce random distractor to make the learning harder.\n",
    "    # For simplicity we will stack the correct key,value answer to first index\n",
    "\n",
    "    # Init records\n",
    "    processed_questions = []\n",
    "    batch_keys = []\n",
    "    batch_values = []\n",
    "    processed_targets = []\n",
    "\n",
    "    # Loop through the batch data\n",
    "    for question, key, value in batch_data:\n",
    "        question = multihot(question,vocab, preserve_counts=True)\n",
    "        processed_questions.append(torch.FloatTensor(question))\n",
    "\n",
    "        # Here on key,value stacks we put correct answer on top index\n",
    "        keys_stack = [key]\n",
    "        values_stack = [value]\n",
    "\n",
    "        # Next we need to generate extra random values\n",
    "        additional_samples = random.sample(train_data, max_key-1)\n",
    "        for _, additional_key, additional_value in additional_samples:\n",
    "            if len(keys_stack) >= max_key:      # in case overflow data\n",
    "                break\n",
    "            # append extra key,value\n",
    "            keys_stack.append(additional_key)\n",
    "            values_stack.append(additional_value)\n",
    "\n",
    "        # BOW\n",
    "        keys_bow = []\n",
    "        values_bow = []\n",
    "        for k, v in zip(keys_stack,values_stack):\n",
    "            k_bow = multihot(k, vocab, preserve_counts= True)\n",
    "            v_bow = multihot(v, vocab, preserve_counts=True)\n",
    "            keys_bow.append(torch.FloatTensor(k_bow))\n",
    "            values_bow.append(torch.FloatTensor(v_bow))\n",
    "\n",
    "        # Append keys and values to processed batch\n",
    "        batch_keys.append(torch.stack(keys_bow))\n",
    "        batch_values.append(torch.stack(values_bow))\n",
    "\n",
    "        processed_targets.append(0)         # correct answer for all questions are in index 0\n",
    "\n",
    "    # Stack batch tensor\n",
    "    processed_questions = torch.stack(processed_questions)\n",
    "    processed_keys = torch.stack(batch_keys)\n",
    "    processed_values = torch.stack(batch_values)\n",
    "    processed_targets = torch.LongTensor(processed_targets)\n",
    "\n",
    "    return processed_questions, processed_keys, processed_values, processed_targets\n",
    "\n",
    "### Training function folr 1 epoch\n",
    "def train_epoch(model, train_data, optimizer, criterion, epoch_count):\n",
    "    # Init\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # Create batches from train_data\n",
    "    batches = split_data_to_batches(train_data, batch_size= 16)\n",
    "    print(f\"Training epoch {epoch_count} and batches {len(batches)}\")\n",
    "    for i, batch in enumerate(batches):\n",
    "        \n",
    "        # Processed data in batch, model we implement in B take separate q,k,v\n",
    "        q,k,v, target = batch_data_processing(batch, VOCAB, max_key=30)         # Higher max key is more challenging and computational\n",
    "\n",
    "        # Move to cuda\n",
    "        # print(device)\n",
    "        q = q.to(device)\n",
    "        k = k.to(device)\n",
    "        v = v.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward\n",
    "        batch_output = model.forward(q,k,v)         # (batch_size, embed_dim)\n",
    "        # print(\"batch output\", batch_output.shape)\n",
    "\n",
    "        # Similar to partC, need an embedding for all values in batch\n",
    "        # Let it go through B, and bmm with the output like the figure in C\n",
    "        values_flat = torch.flatten(v, start_dim=0, end_dim=1)      # flat (batch_size * max_keys, vocab_size)\n",
    "        # print(\"value flat\",values_flat.shape)\n",
    "        embed_batch_value = model.B(values_flat)\n",
    "        # Reshape back after flatten.\n",
    "        embed_batch_value = torch.reshape(embed_batch_value, (v.size(0), v.size(1), -1))        # (batch, max_key, embed_dim)\n",
    "        # print(\"embed_batch value\", embed_batch_value.shape)\n",
    "\n",
    "        # Using bmm to calculate scores/similarity\n",
    "        # batch_output (batch_size, embed_dim)  ---> (batch, 1, embed)\n",
    "        # embed_batch_value (batch, max_key, embed_dim) ---> (batch, embed, max_key)\n",
    "        scores = torch.bmm(batch_output.unsqueeze(1), embed_batch_value.transpose(1,2)).squeeze(1)          # (batch, 1, max_key)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(scores, target)\n",
    "\n",
    "        # Back Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Records keeping\n",
    "        total_count += target.size(0)\n",
    "        total_loss += loss.item()\n",
    "        _, predict = torch.max(scores.data, 1)\n",
    "        correct_count += (predict == target).sum().item()\n",
    "\n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            batch_accuracy = (predict == target).sum().item() / target.size(0)\n",
    "            print(f\"Batch {i}/{len(batches)}, Loss: {loss.item():.4f}, Acc: {batch_accuracy:.2f}\")\n",
    "\n",
    "    avg_loss = total_loss/len(batches)\n",
    "    accuracy = correct_count/total_count\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "### Main\n",
    "\n",
    "print(\"Training\")\n",
    "# Init records keeping for graph\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "epochs = 15\n",
    "\n",
    "# Edit: 7.23 Add learning schedule so it learn faster from begining\n",
    "# Reduce lr by 50% every 3 epoc\n",
    "lr_schedule = StepLR(optimizer, step_size = 3, gamma = 0.5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Train\n",
    "    epoch_loss, epoch_acc = train_epoch(model, train_data, optimizer, criterion,epoch)\n",
    "\n",
    "    # Edit 7.23 decay lr\n",
    "    lr_schedule.step()\n",
    "\n",
    "    # Record for graph later\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} - Loss: {epoch_loss:.2f}, Accuracy: {epoch_acc:.2f}\")\n",
    "\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', marker='o')\n",
    "plt.title('Loss Curve on reduced dataset')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, 'r-', marker='o')\n",
    "plt.title('Training Accuracy on reduced dataset')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g5uXKRAgDjD"
   },
   "source": [
    "**Write the code for testing your model on the test data**\n",
    "\n",
    "Your training loop can call the testing loop. But make sure that you do one last test on the model after training completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "id": "ecGNHCNhTGxK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on 2000 samples\n",
      "Accuracy 73.35000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Testing loop goes here\n",
    "\n",
    "model.eval()\n",
    "correct_count = 0\n",
    "total_count = 0\n",
    "\n",
    "print(f\"Test on {len(test_data)} samples\")\n",
    "\n",
    "# Need to split into batch because out of memory\n",
    "with torch.no_grad():\n",
    "    test_batches = split_data_to_batches(test_data, batch_size=8)\n",
    "    \n",
    "    # Loop though the batch\n",
    "    for data in test_batches:\n",
    "        \n",
    "        q,k,v,target = batch_data_processing(data, VOCAB, max_key= 30)\n",
    "\n",
    "        q = q.to(device)\n",
    "        k = k.to(device)\n",
    "        v = v.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = model.forward(q,k,v)\n",
    "\n",
    "        # Flatten and prepare embeding with B\n",
    "        all_values_flat = torch.flatten(v, start_dim = 0, end_dim = 1)\n",
    "        all_values_embed = model.B(all_values_flat)\n",
    "\n",
    "        # Reshape\n",
    "        all_values_embed = all_values_embed.reshape(v.size(0), v.size(1), -1)\n",
    "\n",
    "        # Compute scores\n",
    "        scores = torch.bmm(output.unsqueeze(1), all_values_embed.transpose(1,2)).squeeze(1)\n",
    "\n",
    "        # Prediction\n",
    "        _, predict = torch.max(scores.data, 1)\n",
    "\n",
    "        # Record keeping\n",
    "        correct_count += (predict == target).sum().item()\n",
    "        total_count += target.size(0)\n",
    "\n",
    "accuracy = correct_count / total_count\n",
    "print(f\"Accuracy {accuracy*100}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSfTnmWbf0Pr"
   },
   "source": [
    "**Suggestion:** Once you have a model that has decent accuracy, you may want to save it to your Google Drive using ``torch.save()`` and load it when working on the next part of the assignment using ``torch.load()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a local path\n",
    "model_path = os.path.join(\"models\", \"trained.pt\")  \n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KVMemNet(\n",
       "  (A): Linear(in_features=37048, out_features=128, bias=True)\n",
       "  (B): Linear(in_features=37048, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "model = KVMemNet(vocab_size, embed_dim)  # use your constructor and same hyperparams\n",
    "\n",
    "# Load saved weights\n",
    "model.load_state_dict(torch.load(\"models/trained.pt\"))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRCn-LZmMNCp"
   },
   "source": [
    "# Part E: Use the Model (5 points)\n",
    "\n",
    "Given a question in natural language, turn it into a bag of words and feed it into the model with a set of plausible keys and values. Apply the output feature embedding to the full set of values and pick the value with argmax. Return the actual text inside that value (not the bag of words or embedding).\n",
    "\n",
    "That is, given a natural language question, you are asked to create the $q$ and pick a relevant subset of $k$ and $v$. Run the $q$, $k$, and $v$ through the model and get an answer to the original question.\n",
    "\n",
    "For example a question might be \"When was Alexander Hamilton born?\" Depending on how you pre-proessed your data, you may need to extract the entity and the relation.\n",
    "\n",
    "Write a function that takes in the `question` below, the data, and the model, and outputs the text answer, e.g., \"11 january 1755\". You must use your ``KVMemNet``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiRYRlRhfFUG"
   },
   "source": [
    "**Suggestion:** To process a question you will probably want to find the entity and the relation. You may use packages such as [NLTK](https://www.nltk.org/) (already imported), [SpaCY](https://spacy.io/), [Stanza](https://stanfordnlp.github.io/stanza/), or other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofPVuNzWeIto"
   },
   "source": [
    "Change the question to test your implementation, but don't delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "id": "JQLNvGsfm3b3"
   },
   "outputs": [],
   "source": [
    "question = \"When was alexander hamilton born?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGSewc7jeaj1"
   },
   "source": [
    "**Create your function for using the `KVMemNet` to answer a given question.**\n",
    "\n",
    "The function should take in the question, data, model, and any other parameters you need. The function should return a text string.\n",
    "\n",
    "You can create as many cells as necessary. Save the notebook cells showing one example of your input question and output answer. For grading we will look to see that your question is in natural language, the model is used, and the answer is in text. The example doesn't have to be correct. You will analyze your technique later in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "id": "sN0ZNtADTzDd"
   },
   "outputs": [],
   "source": [
    "# Create your functions here\n",
    "\n",
    "# Originally I only use pattern recognition/regex to search for relation and name.\n",
    "# Trying to implment nltk to help with tag and recognize name better\n",
    "# lower case is better for regex, but in pos_tag, keep the original question for Capital letter in name\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def extract_name_and_relation(question):\n",
    "    \"\"\"Extract person name and relation type from natural language question\"\"\"\n",
    "    question_lower = question.lower().strip()           # This is set up to use regex for relation, use original q for nltk\n",
    "    # print(question_lower)\n",
    "\n",
    "    # Collect  stop_word, common words with little meaningful content\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Set up relation patterns\n",
    "    relation_patterns = {\n",
    "        'birth_date': [r'when.*born', r'birth.*date', r'date.*birth'],\n",
    "        'birth_place': [r'where.*born', r'birth.*place', r'place.*birth'],\n",
    "        'death_date': [r'when.*die', r'when.*died', r'death.*date', r'date.*death'],\n",
    "        'death_place': [r'where.*die', r'where.*died', r'death.*place', r'place.*death'],\n",
    "        'office': [r'what.*office', r'what.*position', r'what.*job', r'office', r'position'],\n",
    "        'party': [r'what.*party', r'political.*party', r'party'],\n",
    "        'spouse': [r'who.*married', r'who.*spouse', r'spouse', r'married.*to'],\n",
    "        'children': [r'who.*child', r'who.*children', r'sons', r'daughters',r'kids',r'how many.*children'],\n",
    "        'religion': [r'what.*religion', r'religion.*believe', r'faith', r'religious.*beliefs?', r'is.*religion']\n",
    "    }\n",
    "    \n",
    "    # Extract relation from question\n",
    "    result_relation = None\n",
    "    for relation, patterns in relation_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, question_lower):\n",
    "                result_relation = relation\n",
    "                break\n",
    "        if result_relation:\n",
    "            break\n",
    "    \n",
    "    # Name extraction using POS tags\n",
    "    tokens_question_extract = word_tokenize(question)\n",
    "    pos_tags = pos_tag(tokens_question_extract)\n",
    "    # print(pos_tags)\n",
    "    \n",
    "    # Extract name using the tag NNP\n",
    "    name_tokens = [word for word, tag in pos_tags if tag.startswith(\"NNP\") and word.lower() not in stop_words]\n",
    "    result_name = ' '.join(name_tokens) if name_tokens else None\n",
    "    result_name = result_name.lower().strip()           # convert back to lower becase DB name is lower case\n",
    "    \n",
    "    return result_name, result_relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, model, vocab, DB, max_keys=30):\n",
    "    model.eval()\n",
    "\n",
    "    name, relation = extract_name_and_relation(question)\n",
    "    if not name:\n",
    "        return \"Could not extract person from the question.\"\n",
    "    if not relation:\n",
    "        return \"Could not extract relation from the question.\"\n",
    "    print(f\"person: {name}, relation: {relation} detected in question\")\n",
    "\n",
    "\n",
    "    # Get (key, value) pairs from DB\n",
    "    person_data = DB.get(name, {})\n",
    "    if not person_data:\n",
    "        return f\"No information found for '{name}'\"\n",
    "    if relation not in person_data:\n",
    "        return f\"No information found for relation '{relation}'\"\n",
    "\n",
    "    correct_value = person_data[relation]\n",
    "    correct_key = f\"{name} {relation}\"\n",
    "    # Create candidate keys/values pairs\n",
    "    keys = [correct_key]\n",
    "    values = [correct_value]\n",
    "\n",
    "    # Add random key/value from other people in the DB\n",
    "    for other_name, data in DB.items():\n",
    "        if other_name == name:\n",
    "            continue\n",
    "        if relation in data and data[relation] not in values:\n",
    "            random_key = f\"{other_name} {relation}\"\n",
    "            keys.append(random_key)\n",
    "            values.append(data[relation])\n",
    "        if len(keys) >= max_keys:\n",
    "            break\n",
    "    # print(keys)\n",
    "    # print(values)\n",
    "    # Process inputs\n",
    " \n",
    "    question_bow = multihot(question, vocab, preserve_counts=True)\n",
    "    question_vec = torch.FloatTensor(question_bow).unsqueeze(0).to(device)\n",
    "\n",
    "    # Convert the keys and value BOW\n",
    "    # Append and stack them into tensor\n",
    "    keys_bow = []\n",
    "    values_bow = []\n",
    "\n",
    "    for key in keys:\n",
    "        key_bow = multihot(key, vocab, preserve_counts=True)\n",
    "        keys_bow.append(torch.FloatTensor(key_bow))\n",
    "    for value in values:\n",
    "        value_bow = multihot(value, vocab, preserve_counts=True)\n",
    "        values_bow.append(torch.FloatTensor(value_bow))\n",
    "    key_vecs = torch.stack(keys_bow).unsqueeze(0).to(device)\n",
    "    value_vecs = torch.stack(values_bow).unsqueeze(0).to(device)\n",
    "\n",
    "    # Querry process\n",
    "    with torch.no_grad():\n",
    "        model_output = model(question_vec, key_vecs, value_vecs)\n",
    "\n",
    "        # Similar to C, embeding all values in the data, let it pass B layer and compute scores\n",
    "        flattened_values = torch.flatten(value_vecs, start_dim=0, end_dim=1)\n",
    "        value_embeddings = model.B(flattened_values)\n",
    "        value_embeddings = value_embeddings.reshape(value_vecs.size(0), value_vecs.size(1), -1)\n",
    "\n",
    "        scores = torch.bmm(model_output.unsqueeze(1), value_embeddings.transpose(1, 2)).squeeze(1)\n",
    "        _, pred_idx = torch.max(scores.data, dim=1)\n",
    "\n",
    "\n",
    "    # Print correct value and return predicted value\n",
    "    predicted_value = values[pred_idx.item()]\n",
    "    print(\"correct answer:\", correct_value)\n",
    "    return predicted_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j. p. featherston\n",
      "jon tester\n",
      "emanuelis zingeris\n",
      "jean-marie le pen\n",
      "ma lik\n",
      "w. b. kinne\n",
      "antonio nariño\n",
      "chang nien-chung\n",
      "thomas claiborne -lrb- 1749 -- 1812 -rrb-\n",
      "qi jinli\n",
      "merrill i. mills\n",
      "wang guosheng -lrb- politician -rrb-\n",
      "thomas holliday hicks\n",
      "robert smith walker\n",
      "josiah carter\n",
      "pavol hrivnák\n",
      "h. m. fowler\n",
      "kala venkata rao\n",
      "mohammed al-ghabban\n",
      "ian khama\n",
      "joe lesage\n"
     ]
    }
   ],
   "source": [
    "# Print the first 20 person names in the DB\n",
    "for i, name in enumerate(DB.keys()):\n",
    "    print(name)\n",
    "    if i >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: When was Alexander Hamilton born?\n",
      "person: alexander hamilton, relation: birth_date detected in question\n",
      "correct answer: 11 january 1755\n",
      "Answer: 11 january 1755\n",
      "40 max keys\n",
      "Question: When was Alexander Hamilton born?\n",
      "person: alexander hamilton, relation: birth_date detected in question\n",
      "correct answer: 11 january 1755\n",
      "Answer: 06 february 1956\n",
      "100 max keys\n",
      "Question: When was Alexander Hamilton born?\n",
      "person: alexander hamilton, relation: birth_date detected in question\n",
      "correct answer: 11 january 1755\n",
      "Answer: 06 february 1956\n",
      "1000 max keys\n",
      "Question: When was Alexander Hamilton born?\n",
      "person: alexander hamilton, relation: birth_date detected in question\n",
      "correct answer: 11 january 1755\n",
      "Answer: yes 1964\n"
     ]
    }
   ],
   "source": [
    "question = \"When was Alexander Hamilton born?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"40 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=40)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"100 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=100)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"1000 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=1000)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: Do Alexander Hamilton have kids?\n",
      "person: alexander hamilton, relation: children detected in question\n",
      "correct answer: philip angelica alexander james alexander john church william stephen eliza holly phil\n",
      "Answer: nicholas emily gabriel\n",
      "40 max keys\n",
      "Question: Do Alexander Hamilton have kids?\n",
      "person: alexander hamilton, relation: children detected in question\n",
      "correct answer: philip angelica alexander james alexander john church william stephen eliza holly phil\n",
      "Answer: henry with sophia mary with sophia william with sophia howell with sophia elizabeth with mary louise with mary hardind with mary\n",
      "100 max keys\n",
      "Question: Do Alexander Hamilton have kids?\n",
      "person: alexander hamilton, relation: children detected in question\n",
      "correct answer: philip angelica alexander james alexander john church william stephen eliza holly phil\n",
      "Answer: four\n",
      "1000 max keys\n",
      "Question: Do Alexander Hamilton have kids?\n",
      "person: alexander hamilton, relation: children detected in question\n",
      "correct answer: philip angelica alexander james alexander john church william stephen eliza holly phil\n",
      "Answer: violet o liu emmett o liu\n"
     ]
    }
   ],
   "source": [
    "question = \"Do Alexander Hamilton have kids?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"40 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=40)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"100 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=100)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"1000 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=1000)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When was Ma Lik born?\n",
      "person: lik, relation: birth_date detected in question\n",
      "Answer: No information found for 'lik'\n"
     ]
    }
   ],
   "source": [
    "question = \"When was Ma Lik born?\"\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=10)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: When was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_date detected in question\n",
      "correct answer: 23 december 1942\n",
      "Answer: 23 december 1942\n",
      "40 max keys\n",
      "Question: When was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_date detected in question\n",
      "correct answer: 23 december 1942\n",
      "Answer: 23 december 1942\n",
      "100 max keys\n",
      "Question: When was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_date detected in question\n",
      "correct answer: 23 december 1942\n",
      "Answer: 23 december 1942\n",
      "1000 max keys\n",
      "Question: When was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_date detected in question\n",
      "correct answer: 23 december 1942\n",
      "Answer: 02 september 1956\n"
     ]
    }
   ],
   "source": [
    "question = \"When was Robert Smith Walker born?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"40 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=40)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"100 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=100)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"1000 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=1000)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: Where was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_place detected in question\n",
      "correct answer: bradford pennsylvania\n",
      "Answer: bradford pennsylvania\n",
      "40 max keys\n",
      "Question: Where was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_place detected in question\n",
      "correct answer: bradford pennsylvania\n",
      "Answer: bradford pennsylvania\n",
      "100 max keys\n",
      "Question: Where was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_place detected in question\n",
      "correct answer: bradford pennsylvania\n",
      "Answer: bradford pennsylvania\n",
      "1000 max keys\n",
      "Question: Where was Robert Smith Walker born?\n",
      "person: robert smith walker, relation: birth_place detected in question\n",
      "correct answer: bradford pennsylvania\n",
      "Answer: lice diyarbakır province turkey\n"
     ]
    }
   ],
   "source": [
    "question = \"Where was Robert Smith Walker born?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"40 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=40)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"100 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=100)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"1000 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=1000)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: What is Robert Smith Walker office?\n",
      "person: robert smith walker, relation: office detected in question\n",
      "correct answer: republican chief deputy whip of the united states house of representatives\n",
      "Answer: governor of hubei\n",
      "40 max keys\n",
      "Question: What is Robert Smith Walker office?\n",
      "person: robert smith walker, relation: office detected in question\n",
      "correct answer: republican chief deputy whip of the united states house of representatives\n",
      "Answer: president of botswana vice president of botswana\n",
      "100 max keys\n",
      "Question: What is Robert Smith Walker office?\n",
      "person: robert smith walker, relation: office detected in question\n",
      "correct answer: republican chief deputy whip of the united states house of representatives\n",
      "Answer: permanent representative of nepal to the united nations permanent secretary of the ministry of foreign affairs\n",
      "1000 max keys\n",
      "Question: What is Robert Smith Walker office?\n",
      "person: robert smith walker, relation: office detected in question\n",
      "correct answer: republican chief deputy whip of the united states house of representatives\n",
      "Answer: minister of internal affairs of georgia minister of defense of georgia\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Robert Smith Walker office?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"40 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=40)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"100 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=100)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"1000 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=1000)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: Who was Alexander Hamilton spouse?\n",
      "person: alexander hamilton, relation: spouse detected in question\n",
      "correct answer: elizabeth schuyler\n",
      "Answer: elizabeth schuyler\n",
      "40 max keys\n",
      "Question: Who was Alexander Hamilton spouse?\n",
      "person: alexander hamilton, relation: spouse detected in question\n",
      "correct answer: elizabeth schuyler\n",
      "Answer: dr patricia o\n",
      "100 max keys\n",
      "Question: Who was Alexander Hamilton spouse?\n",
      "person: alexander hamilton, relation: spouse detected in question\n",
      "correct answer: elizabeth schuyler\n",
      "Answer: linda\n",
      "1000 max keys\n",
      "Question: Who was Alexander Hamilton spouse?\n",
      "person: alexander hamilton, relation: spouse detected in question\n",
      "correct answer: elizabeth schuyler\n",
      "Answer: elizabeth villiers\n"
     ]
    }
   ],
   "source": [
    "question = \"Who was Alexander Hamilton spouse?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"40 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=40)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"100 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=100)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(f\"1000 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=1000)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: What is Alexander Hamilton religion?\n",
      "person: alexander hamilton, relation: religion detected in question\n",
      "correct answer: presbyterian episcopalian convert\n",
      "Answer: christianity presbyterian\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Alexander Hamilton religion?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: Did Alexander Hamilton have any kid?\n",
      "Answer: Could not extract relation from the question.\n"
     ]
    }
   ],
   "source": [
    "question = \"Did Alexander Hamilton have any kid?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max keys\n",
      "Question: Did Alexander-Hamilton have any kids?\n",
      "person: alexander-hamilton, relation: children detected in question\n",
      "Answer: No information found for 'alexander-hamilton'\n"
     ]
    }
   ],
   "source": [
    "question = \"Did Alexander-Hamilton have any kids?\"\n",
    "print(f\"20 max keys\")\n",
    "print(\"Question:\", question)\n",
    "answer = answer_question(question, model, VOCAB, DB,max_keys=20)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Remark: I tested with multiple max_keys, the numbers of key,value pair added to the querry to make it challenging. With max_keys below <= 20, the prediction is great 50-70%. Increasing max_key above 30, the accuracy start dropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N27-OtrzpT-u"
   },
   "source": [
    "# Part F: Reporting (15 points)\n",
    "\n",
    "Your report should answer the following three questions:\n",
    "\n",
    " **Q1:** What pre-processing of the data did you do? What motivated the design decisions and how did it impact training and any processing of natural language questions (Parts A and D)?\n",
    "\n",
    " Hint: This should help one understand any code modifications you made in Parts A and the first part of Part D. But you shouldn't use this to document your code (hopefully you commented your code with code comments and text cells above), but to justify your choices as well as to explain what worked and what didn't work.\n",
    "\n",
    " **Q2:** Report on your training on the real data (Part D). Show your loss curve and report on the testing accuracy. There are many ways to implement the training loop, particularly with the choice of keys and values. What decisions did you make when developing your training loop? Justify your decisions. How did they impact the training?\n",
    "\n",
    " Hint: This assignment doesn't grade you on how well your model learns---your solution will not be perfect. We focus more on how you worked through the process. This part of the report should show how well your solution worked, but also the intuition for why it works, and to document the things you tried that didn't work.\n",
    "\n",
    " **Q3:** Describe your technique on how you process natural language questions (Part E). Provide some examples of your technique answering questions correctly and some examples of your technique answering questions incorrectly. Discuss what causes the failure cases.\n",
    "\n",
    " Hint: You are not penalized for incorrectly answered questions---your model will not be perfect---we are looking for honest reflection. Preferably, show the example as code blocks running your model with notebook outputs saved.\n",
    "\n",
    " We have provided three prompts below. You can create as many text and code cells as necessary.\n",
    " \n",
    " --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8dovCuyuEvL"
   },
   "source": [
    "**Q1: Report on Data Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qhr3QwvuLBQ"
   },
   "source": [
    "### The original notebook and instruction has proposed an usable pipeline to handle the data. The synthetic data was good until part C. The process is straight forward, we build up a database vocabulary, tokenize database information, understaing the structure of training data which is a triple tensor of question, keys, and values. The following are key pre-processing improvement of the data I impplement and improve in Part A and Part D:\n",
    "#### 1. Reduce vocabulary: \n",
    "Using the reduced vocab function from original code and instruction, I attempt to use a reduced vocab size to remove words that are less meaningful in the library. This was done by filtering out words that appear fewer than 3 times in the VOCAB, reducing from 96k to 47k words (50% reduction). This make the traning much more computaionally feasible while retain most important words in the library.\n",
    "#### 2. Enhanced mulhihot() function\n",
    "Based on suggestion on the notebook we revised the multihot encoding function to handle unknown words, these are words that are out of vocabulary. Because we used reduced vocabulary, there will be more OOV words so and handle it is necessary. This enable a robust processing data using reduced vocab. \n",
    "#### 3. Reduce relations to most common ones.\n",
    "When creating dataset in part D, we limit relations to only 9 most common relation based on common sense. It reduced the dataset complexity and focus more to consistent relations. Some relations are rare so filter them out make training more efficient. The impact is that learning task are more focused on biographical information and training is more efficient.\n",
    "#### 4. Preserve Word counts in Bag of Words\n",
    "So instead of focusing on presence we turn preserve word counts = true to maintain word frequency information to give more weights on important words. Frequent words provide richer semantic information than just word presence. The impact might be better capturing of semantic nuances.\n",
    "\n",
    "The overall impact on training is that memory usage is more efficient, oov words handle prevent crashing. Focusing on common relations helps the model converge faster. Training speed also faster in part D. This also provide a pipeline to process natural language question in part E.\n",
    "\n",
    "\n",
    "### Acknowledge limitation: \n",
    "Aggressive reduced vocabulary may lost rare but meaning words. We have to do it because of limited timing. Domain restriction limit questions on part E when some questions can be answered because relation in the question is not in the domain.\n",
    "\n",
    "---------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VBW1vSduN4U"
   },
   "source": [
    "**Q2: Report on Training and Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT_9MtT2uQ7I"
   },
   "source": [
    "**Model Config and Training**\n",
    "Our reduced vocab size is 47,085. On our training dataset, we limit the people on the list to 40,786. Limit the training data to only 8000 samples and 2000 testing sample.\n",
    "Initially we start with learning rate of 0.0005 but decide to improve with StepLR scheduler to start lr at 0.001 and reduced by half every 3 epochs to help the model learn faster from the begining.\n",
    "Our embedding dimension is 128. Batch size of 16, epoch of 15 and optimizer Adam.\n",
    "\n",
    "**Part D: Data creation**\n",
    "In part D, following the instruction notes and video instruction, we created simple question by concat (name + common relation). Initially we set up the key equal to just name but imrove it by including both name and relation in the key. To prevent overfitting and create challenging for the learner, we randomly select a 'max_keys' number of key,values pairs to add to each querry. For simplicity, we set the correct (key,value) answer to the top, and randomly generate the rest of (key,value) from the database. We observe that higher max_keys makes the learning process more challenging and computational but generalize better. Starting from max_key of 10, we increase it to max_keys 30 in our final run. A querry will have 1 correct (key,value) answer and 29 wrong (key,value) served as distractors. Batching help our model train faster, without it, we wont be able to train more than 10 max_keys in feasiable amount of time.\n",
    "\n",
    "#### Data process and training loop\n",
    "For each epoch, with 8000 samples split into 500 batches of 16 sample each.\n",
    "One each sample, the data consist of 4 elements, question, key, values, and target.\n",
    "The question are generated based on name and relation. We set up the key using the person name and relation as well. Each key are coressponding to a values.\n",
    "For each question, we generate 30 (keys,values) pairs with only 1 correct answer and 29 distractors. By putting the correct answer on index 0, we always select the target element as correct (key,value) pair.\n",
    "\n",
    "The training is bacically using the same KVMnet in part C. Where q,k,v are forward pass through the A layer. All values are embedded and went through B layer where we use to calculate similarity scores with the output from A layer. Finally loss are calculated using CrossEntryLoss with the target.\n",
    "\n",
    "#### Result\n",
    "Our training process show consistent result. With each epoch running 500 batches. With accuracy ramp up from the beginning as expected of StepLR.\n",
    "Epoch 1/15 - Loss: 2.84, Accuracy: 0.12\n",
    "\n",
    "Epoch 2/15 - Loss: 2.22, Accuracy: 0.31\n",
    "\n",
    "Epoch 3/15 - Loss: 1.40, Accuracy: 0.63\n",
    "\n",
    "...\n",
    "\n",
    "Epoch 15/15 - Loss: 0.22, Accuracy: 0.98\n",
    "\n",
    "Our loss curve show consistent downward trend and converging, indicating sucessful learning without obvious overfitting. The graph shows that the model start converging after 10 epoch, which we can stop early but do not have time to do so.\n",
    "When testing on 2000 samples. Our valuation show accuracy of 75%, which is high enough, indicating that training is successful without overfitting.\n",
    "\n",
    "Over the course of training we have implement multiple improvement and the following are what work well:\n",
    "* Batching help to utilize GPU, reduce training time and improve training efficiency.\n",
    "* The key-value random selection approach introduce significant amount of distractors. This taught the model to distinguish between relevant and irrelevant information.\n",
    "* Attention mechanism and used of cross entropy loss help the model learned attention patterns, improve accuracy.\n",
    "* The reduced dataset help training the model more feasiable given limit amount of time.\n",
    "\n",
    "#### Limitation\n",
    "The model is running on reduced vocab and dataset, so even though it generalize well within the reduced dataset. It does not general well in the full data. The reason for this is probably by reducing vocab, we omit rare but important words. We also limit the relation to common ones which makes model perform not well not other rare relations. In part E, we will test it with real questions and people from all the dataset.\n",
    "We also realized that by putting the correct answer on index 0, it simplify our data creation process but it also introduce positional bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', marker='o')\n",
    "plt.title('Loss Curve on reduced dataset')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, 'r-', marker='o')\n",
    "plt.title('Training Accuracy on reduced dataset')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6YimJ0KuScb"
   },
   "source": [
    "_______________________________________________________________________\n",
    "**Q3: Report on Model Use**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1majVIPuVEP"
   },
   "source": [
    "#### Technical Approach:\n",
    "\n",
    "**Person and relation extraction:**\n",
    "\n",
    "We use regular patterns to identify relation type (birth_date, spouse, etc.). Originally, this seem to works but it sometime does not catch name or select non-important words. Based on the suggested note, we use NLTK package to filtering out unimportant words using stopwords. And use the tokenize and taging from NLTK to distinguish noun, verb and name. NLTK seem to capture the person name better.\n",
    "For relation itentification, we still rely on regex and acknowledge that the patterns are limited on what we defined, it will not generalize well on unknown patterns.\n",
    "\n",
    "We use multiple differnt max_keys aka introduce different numbers of distractors, wrong answer to the test to see how the model handle. Because the model was trained with 30 max_keys, it seem to handle question with 30 or less distractors. With higher distractor like over 100, the model structure, which is understandable. There is certain level of generalization achieve here as the model can handle slighly higher max_keys numbers.\n",
    "\n",
    "**Results**\n",
    "Please refer to part E for our test case. Our extraction method seem doing good enough. The model is able to capture name and relation correctly if it is simple and obvious. With harder or complex sentence, it will struggle.\n",
    "For example it cannot capture complex name or name that include different pattern like alexander-hamilton. It have hard time capture non-English name like Ma Lik. This makes sense because our model is trained in English vocabulary.\n",
    "For rare relation, like religion, it also struggle with correct answer.\n",
    "For common relation like bio info that almost everyone has in the data like birth_date, birth_place, etc. it generally do well. In fact, even when increase max_keys to make it more challenging, it can still select the correct answer indicating certain level of generalization achieved.\n",
    "\n",
    "**Limitation**\n",
    "Overall, our model achieve 'not too bad' performance, but it clearly could been improved. First is we can extend our vocabulary and training on full dataset instead of reduced one.\n",
    "Improve the person and relation extractor to better capture relevant and important information from the question/querry.\n",
    "When creating question for training process, we could introduce more complex question and diverse question formats. The current one is too simple.\n",
    "In training process, we can try to alleviate position bias by swap the correct answer position.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "cs7650_HW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
